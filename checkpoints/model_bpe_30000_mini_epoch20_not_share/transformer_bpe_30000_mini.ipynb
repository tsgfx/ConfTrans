{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-26T06:27:25.238875Z",
     "start_time": "2025-02-26T06:27:21.562625Z"
    }
   },
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# 让图形在 Jupyter Notebook 中内嵌显示\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:27:25.278861Z",
     "start_time": "2025-02-26T06:27:25.239886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 打印当前 Python 版本信息\n",
    "print(sys.version_info)\n",
    "\n",
    "# 打印使用库的版本信息\n",
    "for module in mpl, np, pd, sklearn, torch :\n",
    "    print(module.__name__, module.__version__)\n",
    "\n",
    "# 设置 PyTorch 计算设备\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "# 设置随机种子，以保证实验的可复现性\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)"
   ],
   "id": "7ea0c290f8099f6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=12, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.10.0\n",
      "numpy 2.0.2\n",
      "pandas 2.2.3\n",
      "sklearn 1.6.0\n",
      "torch 2.5.1+cu118\n",
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据预处理",
   "id": "b934ba074a83015e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 截取数据集",
   "id": "ff7e9f083c198776"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:27:25.282938Z",
     "start_time": "2025-02-26T06:27:25.279870Z"
    }
   },
   "cell_type": "code",
   "source": "# !python Intercept_dataset_row.py",
   "id": "160d83a5a340bc85",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 划分数据集",
   "id": "19bb399cf83e7041"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:27:25.287008Z",
     "start_time": "2025-02-26T06:27:25.282938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # !python dataset_splitter.py \n",
    "# \n",
    "# # 目标文件夹\n",
    "# output_dir = \"./train_data_size_50000\"\n",
    "# \n",
    "# # 输入文件\n",
    "# src_file = f\"{output_dir}/UNv1.0.en-zh.en\"\n",
    "# tgt_file = f\"{output_dir}/UNv1.0.en-zh.zh\"\n",
    "# \n",
    "# # 输出文件路径\n",
    "# train_src, train_tgt = f\"{output_dir}/train.en\", f\"{output_dir}/train.zh\"\n",
    "# val_src, val_tgt = f\"{output_dir}/val.en\", f\"{output_dir}/val.zh\"\n",
    "# test_src, test_tgt = f\"{output_dir}/test.en\", f\"{output_dir}/test.zh\"\n",
    "# \n",
    "# # 读取所有行\n",
    "# with open(src_file, \"r\", encoding=\"utf-8\") as f_src, open(tgt_file, \"r\", encoding=\"utf-8\") as f_tgt:\n",
    "#     src_lines = f_src.readlines()\n",
    "#     tgt_lines = f_tgt.readlines()\n",
    "# \n",
    "# # 确保行数一致\n",
    "# assert len(src_lines) == len(tgt_lines), \"行数不匹配！\"\n",
    "# \n",
    "# data = list(zip(src_lines, tgt_lines))\n",
    "# \n",
    "# # 划分 90% 训练，5% 验证，5% 测试\n",
    "# total_size = len(data)\n",
    "# train_size = int(total_size * 0.9)\n",
    "# val_size = int(total_size * 0.05)\n",
    "# \n",
    "# train_data = data[:train_size]\n",
    "# val_data = data[train_size:train_size + val_size]\n",
    "# test_data = data[train_size + val_size:]\n",
    "# \n",
    "# # 保存数据\n",
    "# def save_data(file, dataset, idx):\n",
    "#     with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "#         # 使用 tqdm 显示进度条\n",
    "#         for line in tqdm(dataset, desc=f\"Saving {file}\", unit=\"line\"):\n",
    "#             f.write(line[idx])  # idx=0: en, idx=1: zh\n",
    "# \n",
    "# save_data(train_src, train_data, 0)\n",
    "# save_data(train_tgt, train_data, 1)\n",
    "# save_data(val_src, val_data, 0)\n",
    "# save_data(val_tgt, val_data, 1)\n",
    "# save_data(test_src, test_data, 0)\n",
    "# save_data(test_tgt, test_data, 1)\n",
    "# \n",
    "# print(f\"数据集拆分完成，所有文件已保存到 {output_dir} 目录！\")"
   ],
   "id": "392be2ee81a9c212",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Moses&Jieba 分词",
   "id": "c55cfe97251d5cc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:27:25.291422Z",
     "start_time": "2025-02-26T06:27:25.288013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# from tqdm import tqdm\n",
    "# import jieba\n",
    "# from sacremoses import MosesTokenizer\n",
    "# from pathlib import Path\n",
    "# import subprocess\n",
    "# \n",
    "# # 配置目录路径\n",
    "# pair_dir = Path(\"./train_data_size_50000\")  # 双语数据目录\n",
    "# dest_dir = Path(\"./train_data_size_50000_cut\")  # 分词结果目录\n",
    "# \n",
    "# def moses_cut(in_file, out_file, lang):\n",
    "#     \"\"\"\n",
    "#     使用 MosesTokenizer 对输入文件的文本进行分词，并将分词后的结果保存到输出文件中。\n",
    "#     \"\"\"\n",
    "#     mt = MosesTokenizer(lang=lang)\n",
    "#     with open(out_file, \"w\", encoding=\"utf8\") as out_f, open(in_file, \"r\", encoding=\"utf8\") as f:\n",
    "#         lines = f.readlines()\n",
    "#         # 使用 tqdm 来显示处理进度\n",
    "#         for line in tqdm(lines, desc=f\"Moses tokenizing {in_file.name}\", unit=\"line\"):\n",
    "#             line = line.strip()\n",
    "#             if line:\n",
    "#                 cut_line = mt.tokenize(line, return_str=True)\n",
    "#                 out_f.write(cut_line.lower() + \"\\n\")\n",
    "# \n",
    "# def jieba_cut(in_file, out_file):\n",
    "#     \"\"\"\n",
    "#     使用 Jieba 对输入文件的文本进行分词，并将分词后的结果保存到输出文件中。\n",
    "#     \"\"\"\n",
    "#     with open(out_file, \"w\", encoding=\"utf8\") as out_f, open(in_file, \"r\", encoding=\"utf8\") as f:\n",
    "#         lines = f.readlines()\n",
    "#         # 使用 tqdm 来显示处理进度\n",
    "#         for line in tqdm(lines, desc=f\"Jieba tokenizing {in_file.name}\", unit=\"line\"):\n",
    "#             line = line.strip()\n",
    "#             if line:\n",
    "#                 cut_line = \" \".join(jieba.cut(line))\n",
    "#                 out_f.write(cut_line + \"\\n\")\n",
    "# \n",
    "# # 主程序\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 检查目标目录是否存在，如果没有则创建\n",
    "#     dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "# \n",
    "#     # 获取语言对文件所在的目录路径\n",
    "#     local_data_path = pair_dir\n",
    "#     data_dir = dest_dir\n",
    "# \n",
    "#     # 遍历 ['train', 'val', 'test'] 三个数据集模式，分别进行分词处理\n",
    "#     for mode in [\"train\", \"val\", \"test\"]:\n",
    "#         # 对源语言文本进行 Moses 分词处理\n",
    "#         moses_cut(\n",
    "#             local_data_path / f\"{mode}.en\",  # 英文源语言\n",
    "#             data_dir / f\"{mode}_src.cut.txt\",\n",
    "#             lang=\"en\"\n",
    "#         )\n",
    "#         print(f\"[{mode}] English text tokenization completed\")\n",
    "# \n",
    "#         # 对目标语言文本进行 Jieba 分词处理\n",
    "#         jieba_cut(\n",
    "#             local_data_path / f\"{mode}.zh\",  # 中文目标语言\n",
    "#             data_dir / f\"{mode}_trg.cut.txt\"\n",
    "#         )\n",
    "#         print(f\"[{mode}] Chinese text tokenization completed\")\n",
    "# \n",
    "#     print(\"Preprocessing completed.\")"
   ],
   "id": "f21651bdc4e211b4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### BPE 分词",
   "id": "b65b2bad5c8d9b72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:27:25.294306Z",
     "start_time": "2025-02-26T06:27:25.291422Z"
    }
   },
   "cell_type": "code",
   "source": "# !sh double_vocab_bpe_process.sh ./train_data_size_50000 ./train_data_size_50000_cut",
   "id": "b6a3ea0924ea37a5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## DataLoader准备\n",
    "### LangPairDataset"
   ],
   "id": "9baf1472469ce7aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:27:51.610043Z",
     "start_time": "2025-02-26T06:27:51.525159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "dataset_path = \"./train_data_size_50000\"\n",
    "\n",
    "class LangPairDataset(Dataset):\n",
    "    \"\"\"\n",
    "    加载和处理双语数据集，并支持数据缓存。\n",
    "    \"\"\"\n",
    "    def __init__(self, mode=\"train\", max_length=128, overwrite_cache=False, data_dir=dataset_path):\n",
    "        \"\"\"\n",
    "        初始化数据集。\n",
    "        :param mode: 数据集模式（\"train\" 或 \"val\"）\n",
    "        :param max_length: 句子最大长度，超过则过滤\n",
    "        :param overwrite_cache: 是否覆盖缓存，默认为 False\n",
    "        :param data_dir: 数据目录\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)  # 数据存储路径\n",
    "        cache_path = self.data_dir / \".cache\" / f\"de2en_{mode}_{max_length}.npy\"  # 缓存路径\n",
    "        \n",
    "        if overwrite_cache or not cache_path.exists():  # 覆盖缓存或缓存不存在时重新处理\n",
    "            cache_path.parent.mkdir(parents=True, exist_ok=True)  # 创建缓存目录\n",
    "            \n",
    "            # 读取源语言和目标语言文件\n",
    "            with open(self.data_dir / f\"{mode}_src.bpe\", \"r\", encoding=\"utf8\") as file:\n",
    "                self.src = file.readlines()\n",
    "            \n",
    "            with open(self.data_dir / f\"{mode}_trg.bpe\", \"r\", encoding=\"utf8\") as file:\n",
    "                self.trg = file.readlines()\n",
    "            \n",
    "            filtered_src, filtered_trg = [], []  # 存放过滤后的句子\n",
    "            \n",
    "            # 过滤句子长度\n",
    "            for src, trg in zip(self.src, self.trg):\n",
    "                if len(src) <= max_length and len(trg) <= max_length:\n",
    "                    filtered_src.append(src.strip())  # 去除首尾空格\n",
    "                    filtered_trg.append(trg.strip())\n",
    "            \n",
    "            # 保存为 NumPy 数组并缓存\n",
    "            np.save(cache_path, {\"src\": np.array(filtered_src), \"trg\": np.array(filtered_trg)}, allow_pickle=True)\n",
    "            print(f\"save cache to {cache_path}\")\n",
    "        \n",
    "        else:  # 加载已有缓存\n",
    "            cache_dict = np.load(cache_path, allow_pickle=True).item()\n",
    "            print(f\"load {mode} dataset from {cache_path}\")\n",
    "            filtered_src = cache_dict[\"src\"]\n",
    "            filtered_trg = cache_dict[\"trg\"]\n",
    "        \n",
    "        self.src = filtered_src  # 源语言数据\n",
    "        self.trg = filtered_trg  # 目标语言数据\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        获取指定索引的源语言和目标语言句子。\n",
    "        \"\"\"\n",
    "        return self.src[index], self.trg[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集大小。\n",
    "        \"\"\"\n",
    "        return len(self.src)\n",
    "\n",
    "# 创建训练集和验证集对象\n",
    "train_ds = LangPairDataset(\"train\")\n",
    "val_ds = LangPairDataset(\"val\")"
   ],
   "id": "4892cd122f3d3f38",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_data_size_50000\\\\train_src.bpe'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 64\u001B[0m\n\u001B[0;32m     61\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msrc)\n\u001B[0;32m     63\u001B[0m \u001B[38;5;66;03m# 创建训练集和验证集对象\u001B[39;00m\n\u001B[1;32m---> 64\u001B[0m train_ds \u001B[38;5;241m=\u001B[39m \u001B[43mLangPairDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m val_ds \u001B[38;5;241m=\u001B[39m LangPairDataset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[8], line 24\u001B[0m, in \u001B[0;36mLangPairDataset.__init__\u001B[1;34m(self, mode, max_length, overwrite_cache, data_dir)\u001B[0m\n\u001B[0;32m     21\u001B[0m cache_path\u001B[38;5;241m.\u001B[39mparent\u001B[38;5;241m.\u001B[39mmkdir(parents\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)  \u001B[38;5;66;03m# 创建缓存目录\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# 读取源语言和目标语言文件\u001B[39;00m\n\u001B[1;32m---> 24\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_dir\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mmode\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_src.bpe\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msrc \u001B[38;5;241m=\u001B[39m file\u001B[38;5;241m.\u001B[39mreadlines()\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_dir \u001B[38;5;241m/\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_trg.bpe\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n\u001B[1;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'train_data_size_50000\\\\train_src.bpe'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 例子：查看数据集大小\n",
    "print(len(train_ds))\n",
    "print(len(val_ds))\n",
    "for i in range(2):\n",
    "    print(\"source: {}\\ntarget: {}\".format(*train_ds[i]))\n",
    "    print(\"-\"*50)"
   ],
   "id": "a200bc6a2b8a82e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ### Tokenizer",
   "id": "9902f9c937b68aaf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:27:25.431512Z",
     "start_time": "2025-02-26T06:27:25.431512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 构建英文和中文的word2idx和idx2word字典\n",
    "en_word2idx = {\n",
    "    \"[PAD]\": 0,     \n",
    "    \"[BOS]\": 1,     \n",
    "    \"[UNK]\": 2,     \n",
    "    \"[EOS]\": 3,     \n",
    "}\n",
    "zh_word2idx = {\n",
    "    \"[PAD]\": 0,     \n",
    "    \"[BOS]\": 1,     \n",
    "    \"[UNK]\": 2,     \n",
    "    \"[EOS]\": 3,     \n",
    "}\n",
    "\n",
    "# 反向索引\n",
    "en_idx2word = {value: key for key, value in en_word2idx.items()}\n",
    "zh_idx2word = {value: key for key, value in zh_word2idx.items()}\n",
    "\n",
    "# 分别加载英文和中文词表\n",
    "en_index = len(en_idx2word)\n",
    "zh_index = len(zh_idx2word)\n",
    "threshold = 1\n",
    "\n",
    "# 读取英文词表\n",
    "with open(f\"{dataset_path}/en.vocab\", \"r\", encoding=\"utf8\") as file:\n",
    "    for line in tqdm(file.readlines()):\n",
    "        token, counts = line.strip().split()\n",
    "        if int(counts) >= threshold:\n",
    "            en_word2idx[token] = en_index\n",
    "            en_idx2word[en_index] = token\n",
    "            en_index += 1\n",
    "\n",
    "# 读取中文词表  \n",
    "with open(f\"{dataset_path}/zh.vocab\", \"r\", encoding=\"utf8\") as file:\n",
    "    for line in tqdm(file.readlines()):\n",
    "        token, counts = line.strip().split()\n",
    "        if int(counts) >= threshold:\n",
    "            zh_word2idx[token] = zh_index\n",
    "            zh_idx2word[zh_index] = token\n",
    "            zh_index += 1"
   ],
   "id": "6320edf9d082e46e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:27:25.432508Z",
     "start_time": "2025-02-26T06:27:25.432508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, word2idx, idx2word, max_length=128, pad_idx=0, bos_idx=1, eos_idx=3, unk_idx=2):\n",
    "        \"\"\"\n",
    "        初始化 Tokenizer。\n",
    "        :param word2idx: 单词到索引的映射\n",
    "        :param idx2word: 索引到单词的映射\n",
    "        :param max_length: 最大句子长度，超出则截断\n",
    "        :param pad_idx: 填充 token 索引\n",
    "        :param bos_idx: 句子起始 token 索引\n",
    "        :param eos_idx: 句子结束 token 索引\n",
    "        :param unk_idx: 未知单词索引\n",
    "        \"\"\"\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.max_length = max_length\n",
    "        self.pad_idx = pad_idx\n",
    "        self.bos_idx = bos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.unk_idx = unk_idx\n",
    "\n",
    "    def encode(self, text_list, padding_first=False, add_bos=True, add_eos=True, return_mask=False):\n",
    "        \"\"\"\n",
    "        将文本列表编码为索引列表。\n",
    "        :param text_list: 文本列表，每个元素是一个单词列表\n",
    "        :param padding_first: 是否将 [PAD] 填充到句首\n",
    "        :param add_bos: 是否添加 [BOS] 起始符号\n",
    "        :param add_eos: 是否添加 [EOS] 结束符号\n",
    "        :param return_mask: 是否返回 mask\n",
    "        :return: 编码后的 input_ids 或 (input_ids, masks)\n",
    "        \"\"\"\n",
    "        max_length = min(self.max_length, add_eos + add_bos + max([len(text) for text in text_list]))\n",
    "        indices_list = []\n",
    "\n",
    "        for text in text_list:\n",
    "            indices = [self.word2idx.get(word, self.unk_idx) for word in text[:max_length - add_bos - add_eos]]\n",
    "            if add_bos: indices = [self.bos_idx] + indices\n",
    "            if add_eos: indices = indices + [self.eos_idx]\n",
    "\n",
    "            # 填充到 max_length\n",
    "            if padding_first:\n",
    "                indices = [self.pad_idx] * (max_length - len(indices)) + indices\n",
    "            else:\n",
    "                indices = indices + [self.pad_idx] * (max_length - len(indices))\n",
    "\n",
    "            indices_list.append(indices)\n",
    "\n",
    "        input_ids = torch.tensor(indices_list) # 转换为 tensor\n",
    "        masks = (input_ids == self.pad_idx).to(dtype=torch.int64)  # 生成 mask，标记 padding 部分\n",
    "\n",
    "        return input_ids if not return_mask else (input_ids, masks)\n",
    "\n",
    "    def decode(self, indices_list, remove_bos=True, remove_eos=True, remove_pad=True, split=False):\n",
    "        \"\"\"\n",
    "        解码索引列表为文本列表。\n",
    "        :param indices_list: 索引列表\n",
    "        :param remove_bos: 是否移除 [BOS] \n",
    "        :param remove_eos: 是否移除 [EOS]\n",
    "        :param remove_pad: 是否移除 [PAD]\n",
    "        :param split: 是否返回分词列表\n",
    "        :return: 解码后的文本列表\n",
    "        \"\"\"\n",
    "        text_list = []\n",
    "\n",
    "        for indices in indices_list:\n",
    "            text = []\n",
    "            for index in indices:\n",
    "                word = self.idx2word.get(index, \"[UNK]\")  # 获取单词\n",
    "                if remove_bos and word == \"[BOS]\": continue\n",
    "                if remove_eos and word == \"[EOS]\": break\n",
    "                if remove_pad and word == \"[PAD]\": break\n",
    "                text.append(word)\n",
    "\n",
    "            text_list.append(\" \".join(text) if not split else text)\n",
    "\n",
    "        return text_list"
   ],
   "id": "ff0473d08da12b51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T06:27:25.432508Z",
     "start_time": "2025-02-26T06:27:25.432508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建英文和中文的tokenizer\n",
    "en_tokenizer = Tokenizer(word2idx=en_word2idx, idx2word=en_idx2word)\n",
    "zh_tokenizer = Tokenizer(word2idx=zh_word2idx, idx2word=zh_idx2word)\n",
    "\n",
    "# 输出词表大小\n",
    "en_vocab_size = len(en_word2idx)\n",
    "zh_vocab_size = len(zh_word2idx)\n",
    "print(\"en_vocab_size: {}\".format(en_vocab_size))  # 打印英文词表大小\n",
    "print(\"zh_vocab_size: {}\".format(zh_vocab_size))  # 打印中文词表大小"
   ],
   "id": "d020a4b0bcfeb51c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transformer Batch Sampler",
   "id": "b570d392dee27856"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SampleInfo:\n",
    "    def __init__(self, i, lens):\n",
    "        \"\"\"\n",
    "        记录文本对的序号和长度信息。\n",
    "        \n",
    "        :param i: 文本对的序号。\n",
    "        :param lens: 文本对的长度，包含源语言和目标语言的长度。\n",
    "        \"\"\"\n",
    "        self.i = i\n",
    "        # 加一是为了考虑填充的特殊词元，lens[0] 和 lens[1] 分别表示源语言和目标语言的长度\n",
    "        self.max_len = max(lens[0], lens[1]) + 1\n",
    "        self.src_len = lens[0] + 1\n",
    "        self.trg_len = lens[1] + 1\n",
    "\n",
    "\n",
    "class TokenBatchCreator:\n",
    "    def __init__(self, batch_size):\n",
    "        \"\"\"\n",
    "        根据词元数目限制批量大小，并初始化批量存储结构。\n",
    "\n",
    "        :param batch_size: 批量的最大大小。\n",
    "        \"\"\"\n",
    "        self._batch = []  # 当前处理的样本\n",
    "        self.max_len = -1  # 当前批量的最大长度\n",
    "        self._batch_size = batch_size  # 批量大小限制\n",
    "\n",
    "    def append(self, info: SampleInfo):\n",
    "        \"\"\"\n",
    "        将样本信息添加到批量中。如果当前批量大小超过限制，则返回当前批量并创建新批量。\n",
    "\n",
    "        :param info: 包含文本对长度信息的 SampleInfo 对象。\n",
    "        :return: 当前批量样本，如果超过限制，则返回并重置批量，否则返回 None。\n",
    "        \"\"\"\n",
    "        cur_len = info.max_len  # 当前样本的最大长度\n",
    "        max_len = max(self.max_len, cur_len)  # 更新当前批量的最大长度\n",
    "\n",
    "        # 如果当前批量加入新样本后超过限制，返回当前批量并重置\n",
    "        if max_len * (len(self._batch) + 1) > self._batch_size:\n",
    "            self._batch, result = [], self._batch  # 保存当前样本并清空\n",
    "            self._batch.append(info)  # 新批量的第一条样本\n",
    "            self.max_len = cur_len  # 当前批量的最大长度为新样本的最大长度\n",
    "            return result\n",
    "        else:\n",
    "            self.max_len = max_len\n",
    "            self._batch.append(info)  # 将新样本加入当前批量\n",
    "            return None\n",
    "\n",
    "    @property\n",
    "    def batch(self):\n",
    "        return self._batch"
   ],
   "id": "5c67080f63578e89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import BatchSampler\n",
    "import numpy as np\n",
    "\n",
    "class TransformerBatchSampler(BatchSampler):\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 batch_size,\n",
    "                 shuffle_batch=False,\n",
    "                 clip_last_batch=False,\n",
    "                 seed=0):\n",
    "        \"\"\"\n",
    "        批量采样器，用于按批次生成样本。\n",
    "\n",
    "        :param dataset: 数据集\n",
    "        :param batch_size: 每个批次的样本数量\n",
    "        :param shuffle_batch: 是否对批次进行洗牌\n",
    "        :param clip_last_batch: 是否裁剪最后一个批次的数据（如果样本数不足一个完整批次）\n",
    "        :param seed: 随机数种子，用于保证可重复性\n",
    "        \"\"\"\n",
    "        self._dataset = dataset\n",
    "        self._batch_size = batch_size\n",
    "        self._shuffle_batch = shuffle_batch\n",
    "        self._clip_last_batch = clip_last_batch\n",
    "        self._seed = seed\n",
    "        self._random = np.random\n",
    "        self._random.seed(seed)\n",
    "\n",
    "        self._sample_infos = []\n",
    "        # 创建样本信息列表，包含每个样本的索引和长度信息\n",
    "        for i, data in enumerate(self._dataset):\n",
    "            lens = [len(data[0]), len(data[1])]  # 计算样本的源语言和目标语言的长度\n",
    "            self._sample_infos.append(SampleInfo(i, lens)) # 保存为 [索引，样本长度]的格式\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        对数据集中的样本进行排序，并使用 TokenBatchCreator 生成批次。\n",
    "\n",
    "        排序规则：先按源语言长度排序，若源语言长度相同，再按目标语言长度排序。\n",
    "        生成的批次如果未裁剪最后一批，则将剩余样本组成最后一个批次。\n",
    "        如果需要洗牌，则对批次进行洗牌。\n",
    "        \n",
    "        :yield: 每个批次的样本在数据集中的索引\n",
    "        \"\"\"\n",
    "        # 按源语言和目标语言长度排序\n",
    "        infos = sorted(self._sample_infos, key=lambda x: (x.src_len, x.trg_len))\n",
    "        batch_infos = []\n",
    "        batch_creator = TokenBatchCreator(self._batch_size)  # 批量生成器\n",
    "\n",
    "        # 逐个样本加入批量生成器\n",
    "        for info in infos:\n",
    "            batch = batch_creator.append(info)\n",
    "            if batch is not None:\n",
    "                batch_infos.append(batch)  # 每当批次满足要求时，保存当前批次\n",
    "\n",
    "        # 如果未裁剪最后一个批次且有剩余样本，则将剩余样本作为最后一个批次\n",
    "        if not self._clip_last_batch and len(batch_creator.batch) != 0:\n",
    "            batch_infos.append(batch_creator.batch)\n",
    "\n",
    "        # 打乱批次顺序\n",
    "        if self._shuffle_batch:\n",
    "            self._random.shuffle(batch_infos)\n",
    "\n",
    "        # 记录批次数量\n",
    "        self.batch_number = len(batch_infos)\n",
    "\n",
    "        # 生成批次中的样本索引\n",
    "        for batch in batch_infos:\n",
    "            batch_indices = [info.i for info in batch]  # 获取当前批次的样本索引\n",
    "            yield batch_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回批次数量\n",
    "        \"\"\"\n",
    "        if hasattr(self, \"batch_number\"):\n",
    "            return self.batch_number\n",
    "\n",
    "        # 如果没有记录批次数量，计算批次样本数量\n",
    "        batch_number = (len(self._dataset) + self._batch_size - 1) // self._batch_size\n",
    "        return batch_number"
   ],
   "id": "8455ce82888b56d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 创建一个 TransformerBatchSampler 实例，用于从训练数据集 train_ds 中按批次采样样本\n",
    "sampler = TransformerBatchSampler(\n",
    "    train_ds,  # 训练数据集，包含源语言和目标语言的样本\n",
    "    batch_size=4096,  # 每个批次包含的样本数量，设定为 4096\n",
    "    shuffle_batch=True  # 是否对批次进行洗牌，设定为 True，即每次迭代时都会打乱批次顺序\n",
    ")\n",
    "# 例子： 打印一个批次的样本索引\n",
    "for idx, batch in enumerate(sampler):\n",
    "    print(\"第{}批量的数据中含有文本对的索引是：{}，当前批次样本数量为：{}\".format(idx, batch, len(batch)))\n",
    "    break\n",
    "for i in batch:\n",
    "    print(f\"{i}: {train_ds[i]}\\n\");\n",
    "total_len = 0;"
   ],
   "id": "2ee2d7cfa13fccb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DataLoader",
   "id": "733964ae297ff8d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from functools import partial # 固定collate_fct的tokenizer参数\n",
    "def collate_fct(batch, en_tokenizer, zh_tokenizer):\n",
    "    # 分别对源语言(英文)和目标语言(中文)进行处理\n",
    "    src_words = [pair[0].split() for pair in batch]\n",
    "    trg_words = [pair[1].split() for pair in batch]\n",
    "\n",
    "    # 使用英文tokenizer处理源语言\n",
    "    encoder_inputs, encoder_inputs_mask = en_tokenizer.encode(\n",
    "        src_words, padding_first=False, add_bos=True, add_eos=True, return_mask=True\n",
    "    )\n",
    "\n",
    "    # 使用中文tokenizer处理目标语言\n",
    "    decoder_inputs = zh_tokenizer.encode(\n",
    "        trg_words, padding_first=False, add_bos=True, add_eos=False, return_mask=False,\n",
    "    )\n",
    "    \n",
    "    decoder_labels, decoder_labels_mask = zh_tokenizer.encode(\n",
    "        trg_words, padding_first=False, add_bos=False, add_eos=True, return_mask=True\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"encoder_inputs\": encoder_inputs.to(device=device),\n",
    "        \"encoder_inputs_mask\": encoder_inputs_mask.to(device=device),\n",
    "        \"decoder_inputs\": decoder_inputs.to(device=device),\n",
    "        \"decoder_labels\": decoder_labels.to(device=device),\n",
    "        \"decoder_labels_mask\": decoder_labels_mask.to(device=device),\n",
    "    }"
   ],
   "id": "3d0c30ee420d4ec7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 例子：查看编码后的批次数据\n",
    "#可以调大batch_size,来看最终的bleu，如果GPU内存不够，可以减小batch_size\n",
    "sampler = TransformerBatchSampler(train_ds, batch_size=256, shuffle_batch=True)\n",
    "#partial函数，固定collate_fct的tokenizer参数\n",
    "sample_dl = DataLoader(train_ds, batch_sampler=sampler, collate_fn=partial(collate_fct, en_tokenizer=en_tokenizer, zh_tokenizer=zh_tokenizer)) \n",
    "\n",
    "for batch in sample_dl:#外层是拿每个batch\n",
    "    for key, value in batch.items():#内层是拿每个batch里面是一个字典\n",
    "        print(key)\n",
    "        print(value)\n",
    "        print(value.shape)\n",
    "    break"
   ],
   "id": "e741b8e898efeb46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 定义模型",
   "id": "3a182c5d176092d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Embedding",
   "id": "8b04813e382404cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "    def __init__(self, config, vocab_size):\n",
    "        super().__init__()\n",
    "        # 获取配置中的超参数\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = config[\"d_model\"]\n",
    "        self.pad_idx = config[\"pad_idx\"]\n",
    "        dropout_rate = config[\"dropout\"]\n",
    "        self.max_length = config[\"max_length\"]\n",
    "\n",
    "        # 词嵌入层，padding_idx为pad的索引\n",
    "        self.word_embedding = nn.Embedding(self.vocab_size, self.hidden_size, padding_idx=self.pad_idx)\n",
    "        # 位置嵌入层，权重由get_positional_encoding计算得到\n",
    "        self.pos_embedding = nn.Embedding(\n",
    "            self.max_length,\n",
    "            self.hidden_size,\n",
    "            _weight=self.get_positional_encoding(self.max_length, self.hidden_size)\n",
    "        )\n",
    "        self.pos_embedding.weight.requires_grad_(False)  # 位置编码不可训练\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Dropout层\n",
    "\n",
    "    def get_word_embedding_weights(self):\n",
    "        # 返回词嵌入层的权重\n",
    "        return self.word_embedding.weight\n",
    "\n",
    "    @classmethod\n",
    "    def get_positional_encoding(self, max_length, hidden_size):\n",
    "        \"\"\"\n",
    "        计算位置编码\n",
    "        使用正弦和余弦函数生成位置编码矩阵\n",
    "        \"\"\"\n",
    "        pe = torch.zeros(max_length, hidden_size)\n",
    "        position = torch.arange(0, max_length).unsqueeze(1)  # 位置索引\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, hidden_size, 2) * -(torch.log(torch.Tensor([10000.0])) / hidden_size)\n",
    "        )\n",
    "        # 填充位置编码矩阵\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # 偶数列为sin\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # 奇数列为cos\n",
    "        return pe\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        前向传播：词向量与位置编码加和\n",
    "        \"\"\"\n",
    "        seq_len = input_ids.shape[1]  # 序列长度\n",
    "        assert seq_len <= self.max_length, f\"序列长度超出最大限制 {self.max_length}\"\n",
    "\n",
    "        # 生成位置id\n",
    "        position_ids = torch.arange(seq_len, dtype=torch.long, device=input_ids.device) # [seq_len]\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)  # [batch_size, seq_len]\n",
    "\n",
    "        # 获取词嵌入和位置编码\n",
    "        word_embeds = self.word_embedding(input_ids) # [batch_size, seq_len, hidden_size]\n",
    "        pos_embeds = self.pos_embedding(position_ids) # [batch_size, seq_len, hidden_size]\n",
    "        embeds = word_embeds + pos_embeds  # 加和词向量和位置编码\n",
    "        embeds = self.dropout(embeds)  # 应用dropout\n",
    "        return embeds  # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "\n",
    "def plot_position_embedding(position_embedding):\n",
    "    \"\"\"\n",
    "    绘制位置编码矩阵\n",
    "    \"\"\"\n",
    "    plt.pcolormesh(position_embedding)  # 绘制矩阵\n",
    "    plt.xlabel('Depth')  # x轴为深度\n",
    "    plt.ylabel('Position')  # y轴为位置\n",
    "    plt.colorbar()  # 显示颜色条\n",
    "    plt.show()  # 显示图像"
   ],
   "id": "bd57c110b91e2fb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 例子：获取64个位置、128维词向量的位置编码矩阵并绘制\n",
    "position_embedding = TransformerEmbedding.get_positional_encoding(64, 128)\n",
    "plot_position_embedding(position_embedding)"
   ],
   "id": "49a6c190f5a92b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transformer",
   "id": "b1cb752dfcdf7f80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Scaled Dot Product Attention",
   "id": "8f99de547b07abe2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "@dataclass\n",
    "class AttentionOutput:\n",
    "    hidden_states: Tensor  # 注意力层的最终输出\n",
    "    attn_scores: Tensor    # 计算得到的注意力权重\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # 获取配置中的超参数\n",
    "        self.hidden_size = config[\"d_model\"]\n",
    "        self.num_heads = config[\"num_heads\"]\n",
    "        \n",
    "        # 确保 hidden_size 可以被 num_heads 整除\n",
    "        assert self.hidden_size % self.num_heads == 0, \"Hidden size must be divisible by num_heads\"\n",
    "\n",
    "        self.head_dim = self.hidden_size // self.num_heads  # 每个头的维度\n",
    "\n",
    "        # 定义线性变换层\n",
    "        self.Wq = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.Wk = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.Wv = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.Wo = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "\n",
    "    def _split_heads(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        将输入张量拆分为多个头\n",
    "        \"\"\"\n",
    "        bs, seq_len, _ = x.shape\n",
    "        x = x.view(bs, seq_len, self.num_heads, self.head_dim)  # 调整形状\n",
    "        return x.permute(0, 2, 1, 3)  # 调整维度顺序\n",
    "\n",
    "    def _merge_heads(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        合并多个头的输出\n",
    "        \"\"\"\n",
    "        bs, _, seq_len, _ = x.shape\n",
    "        return x.permute(0, 2, 1, 3).reshape(bs, seq_len, self.hidden_size)\n",
    "\n",
    "    def forward(self, querys, keys, values, attn_mask=None) -> AttentionOutput:\n",
    "        \"\"\"\n",
    "        前向传播计算注意力机制\n",
    "        \"\"\"\n",
    "        # 线性变换并拆分为多个头\n",
    "        querys = self._split_heads(self.Wq(querys))  # [batch_size, num_heads, seq_len, head_dim]\n",
    "        keys = self._split_heads(self.Wk(keys))      # [batch_size, num_heads, seq_len, head_dim]\n",
    "        values = self._split_heads(self.Wv(values))  # [batch_size, num_heads, seq_len, head_dim]\n",
    "\n",
    "        # 计算 Q 和 K 之间的点积注意力分数\n",
    "        qk_logits = torch.matmul(querys, keys.mT)  # [batch_size, num_heads, seq_len, seq_len]\n",
    "\n",
    "        # 如果提供了mask，应用它\n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask[:, :, : querys.shape[-2], : keys.shape[-2]]  # 调整mask的大小\n",
    "            qk_logits += attn_mask * -1e9  # mask部分置为负无穷\n",
    "\n",
    "        # 计算注意力权重\n",
    "        attn_scores = F.softmax(qk_logits / (self.head_dim**0.5), dim=-1)  # [batch_size, num_heads, seq_len, seq_len]\n",
    "\n",
    "        # 加权求和\n",
    "        embeds = torch.matmul(attn_scores, values)  # [batch_size, num_heads, seq_len, head_dim]\n",
    "\n",
    "        # 合并头的输出并通过输出投影层\n",
    "        embeds = self.Wo(self._merge_heads(embeds))  # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        return AttentionOutput(hidden_states=embeds, attn_scores=attn_scores)"
   ],
   "id": "7b0f0f610fd6a8ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Transformer Block",
   "id": "5f1c8ed655b4ba8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class TransformerBlockOutput:\n",
    "    # 当前块的输出（隐藏状态）和自/交叉注意力的分数\n",
    "    hidden_states: Tensor\n",
    "    self_attn_scores: Tensor\n",
    "    cross_attn_scores: Optional[Tensor] = None\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config, add_cross_attention=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # 获取配置中的超参数\n",
    "        self.hidden_size = config[\"d_model\"]\n",
    "        self.num_heads = config[\"num_heads\"]\n",
    "        dropout_rate = config[\"dropout\"]\n",
    "        ffn_dim = config[\"dim_feedforward\"]\n",
    "        eps = config[\"layer_norm_eps\"]\n",
    "\n",
    "        # 自注意力机制\n",
    "        self.self_atten = MultiHeadAttention(config)\n",
    "        self.self_ln = nn.LayerNorm(self.hidden_size, eps=eps)\n",
    "        self.self_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # 交叉注意力机制（仅解码器中使用）\n",
    "        if add_cross_attention:\n",
    "            self.cross_atten = MultiHeadAttention(config)\n",
    "            self.cross_ln = nn.LayerNorm(self.hidden_size, eps=eps)\n",
    "            self.cross_dropout = nn.Dropout(dropout_rate)\n",
    "        else:\n",
    "            self.cross_atten = None\n",
    "\n",
    "        # 前馈神经网络（FFN）\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, ffn_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ffn_dim, self.hidden_size),\n",
    "        )\n",
    "        self.ffn_ln = nn.LayerNorm(self.hidden_size, eps=eps)\n",
    "        self.ffn_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, hidden_states, attn_mask=None, encoder_outputs=None, cross_attn_mask=None):\n",
    "        # 自注意力机制\n",
    "        self_atten_output = self.self_atten(\n",
    "            hidden_states, hidden_states, hidden_states, attn_mask\n",
    "        )\n",
    "        self_embeds = self.self_ln(\n",
    "            hidden_states + self.self_dropout(self_atten_output.hidden_states)\n",
    "        )\n",
    "\n",
    "        # 交叉注意力机制（解码器中）\n",
    "        if self.cross_atten is not None:\n",
    "            assert encoder_outputs is not None  # 使用交叉注意力时，必须传入编码器输出\n",
    "            cross_atten_output = self.cross_atten(\n",
    "                self_embeds, encoder_outputs, encoder_outputs, cross_attn_mask\n",
    "            )\n",
    "            cross_embeds = self.cross_ln(\n",
    "                self_embeds + self.cross_dropout(cross_atten_output.hidden_states)\n",
    "            )\n",
    "\n",
    "        # 前馈神经网络（FFN）\n",
    "        embeds = cross_embeds if self.cross_atten is not None else self_embeds\n",
    "        ffn_output = self.ffn(embeds)\n",
    "        embeds = self.ffn_ln(embeds + self.ffn_dropout(ffn_output))\n",
    "\n",
    "        # 返回 TransformerBlockOutput\n",
    "        return TransformerBlockOutput(\n",
    "            hidden_states=embeds,\n",
    "            self_attn_scores=self_atten_output.attn_scores,\n",
    "            cross_attn_scores=cross_atten_output.attn_scores if self.cross_atten is not None else None,\n",
    "        )"
   ],
   "id": "315d0c77f5c2652c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Encoder",
   "id": "f6c06503b7815611"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "\n",
    "@dataclass  # 存储TransformerEncoder的输出\n",
    "class TransformerEncoderOutput:\n",
    "    last_hidden_states: Tensor  # 最后一层的隐藏状态，包含上下文信息\n",
    "    attn_scores: List[Tensor]   # 每层的注意力分数，用于分析每层的关注点\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        # 获取编码器层数\n",
    "        self.num_layers = config[\"num_encoder_layers\"]\n",
    "\n",
    "        # 创建包含多个TransformerBlock的列表，每个TransformerBlock代表编码器的一层\n",
    "        self.layers = nn.ModuleList(\n",
    "            [TransformerBlock(config) for _ in range(self.num_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, encoder_inputs_embeds, attn_mask=None) -> TransformerEncoderOutput:\n",
    "        attn_scores = []  # 存储每层的自注意力分数\n",
    "        embeds = encoder_inputs_embeds  # 输入嵌入作为编码器的第一层输入\n",
    "\n",
    "        # 遍历每一层TransformerBlock\n",
    "        for layer in self.layers:\n",
    "            block_outputs = layer(embeds, attn_mask=attn_mask)  # 当前层输出\n",
    "            \n",
    "            embeds = block_outputs.hidden_states  # 更新下一层输入\n",
    "            attn_scores.append(block_outputs.self_attn_scores)  # 保存注意力分数\n",
    "\n",
    "        # 返回最后一层输出和所有层的注意力分数\n",
    "        return TransformerEncoderOutput(\n",
    "            last_hidden_states=embeds,  # 最后一层的输出\n",
    "            attn_scores=attn_scores  # 所有层的注意力分数\n",
    "        )"
   ],
   "id": "70aa1fe1c5d89641",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Decoder",
   "id": "138185edf3d182fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class TransformerDecoderOutput:\n",
    "    last_hidden_states: Tensor  # 最后一层的隐藏状态\n",
    "    self_attn_scores: List[Tensor]  # 每层的自注意力分数\n",
    "    cross_attn_scores: List[Tensor]  # 每层的交叉注意力分数\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 获取解码器层数\n",
    "        self.num_layers = config[\"num_decoder_layers\"]\n",
    "\n",
    "        # 创建多个TransformerBlock，每层都有交叉注意力机制\n",
    "        self.layers = nn.ModuleList(\n",
    "            [TransformerBlock(config, add_cross_attention=True) for _ in range(self.num_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, decoder_inputs_embeds, encoder_outputs, attn_mask=None, cross_attn_mask=None) -> TransformerDecoderOutput:\n",
    "        self_attn_scores = []  # 存储每层的自注意力分数\n",
    "        cross_attn_scores = []  # 存储每层的交叉注意力分数\n",
    "        embeds = decoder_inputs_embeds  # 解码器输入嵌入\n",
    "\n",
    "        # 遍历每一层的TransformerBlock\n",
    "        for layer in self.layers:\n",
    "            # 前向传播，通过自注意力和交叉注意力机制\n",
    "            block_outputs = layer(\n",
    "                embeds,\n",
    "                attn_mask=attn_mask,\n",
    "                encoder_outputs=encoder_outputs,\n",
    "                cross_attn_mask=cross_attn_mask,\n",
    "            )\n",
    "            embeds = block_outputs.hidden_states  # 更新输入为当前层输出\n",
    "\n",
    "            self_attn_scores.append(block_outputs.self_attn_scores)  # 保存自注意力分数\n",
    "            cross_attn_scores.append(block_outputs.cross_attn_scores)  # 保存交叉注意力分数\n",
    "\n",
    "        # 返回最后一层的隐藏状态和每层的注意力分数\n",
    "        return TransformerDecoderOutput(\n",
    "            last_hidden_states=embeds, \n",
    "            self_attn_scores=self_attn_scores,\n",
    "            cross_attn_scores=cross_attn_scores\n",
    "        )"
   ],
   "id": "40b6404562f388b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Mask",
   "id": "face90cdad3c5be4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    生成方形的后续掩码，屏蔽掉当前及之前的元素。\n",
    "    掩码位置为 True，未屏蔽的为 False。\n",
    "    \"\"\"\n",
    "    # 创建上三角矩阵并取反，形成掩码\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 0).transpose(-1, -2).bool()\n",
    "    return mask"
   ],
   "id": "c5e236846488087b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Transformer Model",
   "id": "954c5e61eaa76cbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class TransformerOutput:\n",
    "    logits: Tensor  # 模型的预测输出 logits\n",
    "    encoder_last_hidden_states: Tensor  # 编码器的最终隐藏状态\n",
    "    encoder_attn_scores: List[Tensor]  # 编码器各层的自注意力得分\n",
    "    decoder_last_hidden_states: Tensor  # 解码器的最终隐藏状态\n",
    "    decoder_self_attn_scores: List[Tensor]  # 解码器自注意力得分\n",
    "    decoder_cross_attn_scores: List[Tensor]  # 解码器交叉注意力得分\n",
    "    preds: Optional[Tensor] = None  # 推理时的预测结果\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # 模型的各项配置初始化\n",
    "        self.hidden_size = config[\"d_model\"]  # Transformer模型中的隐藏层维度\n",
    "        self.num_encoder_layers = config[\"num_encoder_layers\"]  # 编码器层数\n",
    "        self.num_decoder_layers = config[\"num_decoder_layers\"]  # 解码器层数\n",
    "        self.pad_idx = config[\"pad_idx\"]  # padding 标记的索引\n",
    "        self.bos_idx = config[\"bos_idx\"]  # 句子开始标记的索引\n",
    "        self.eos_idx = config[\"eos_idx\"]  # 句子结束标记的索引\n",
    "        self.en_vocab_size = config[\"en_vocab_size\"]  # 英文词表大小\n",
    "        self.zh_vocab_size = config[\"zh_vocab_size\"]  # 中文词表大小\n",
    "        self.dropout_rate = config[\"dropout\"]  # Dropout比例\n",
    "        self.max_length = config[\"max_length\"]  # 最大序列长度\n",
    "\n",
    "        # 初始化源语言(英文)和目标语言(中文)的嵌入层\n",
    "        self.src_embedding = TransformerEmbedding(config, vocab_size=self.en_vocab_size)\n",
    "        self.trg_embedding = TransformerEmbedding(config, vocab_size=self.zh_vocab_size)\n",
    "        \n",
    "        # 输出层的线性变换，输出的维度为中文词表大小\n",
    "        self.linear = nn.Linear(self.hidden_size, self.zh_vocab_size)\n",
    "\n",
    "        # 初始化编码器和解码器\n",
    "        self.encoder = TransformerEncoder(config)\n",
    "        self.decoder = TransformerDecoder(config)\n",
    "        \n",
    "        # 权重初始化\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"初始化网络权重\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                # 使用 Xavier 均匀分布初始化权重\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz: int) -> Tensor:\n",
    "        \"\"\"生成解码器的下三角掩码，用于自回归解码\"\"\"\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 0).transpose(-1, -2).bool()  # 下三角掩码\n",
    "        return mask\n",
    "\n",
    "    def forward(self, encoder_inputs, decoder_inputs, encoder_inputs_mask=None) -> TransformerOutput:\n",
    "        \"\"\"\n",
    "        Transformer前向传播\n",
    "        1. 将输入的源语言和目标语言进行嵌入。\n",
    "        2. 通过编码器处理源语言输入。\n",
    "        3. 通过解码器生成目标语言的输出。\n",
    "        \"\"\"\n",
    "        if encoder_inputs_mask is None:\n",
    "            # 如果没有提供mask，则根据padding索引生成\n",
    "            encoder_inputs_mask = encoder_inputs.eq(self.pad_idx)\n",
    "        encoder_inputs_mask = encoder_inputs_mask.unsqueeze(1).unsqueeze(2)  # 扩展mask维度，以适应多头注意力\n",
    "\n",
    "        # 生成解码器掩码（防止信息泄漏）\n",
    "        look_ahead_mask = self.generate_square_subsequent_mask(decoder_inputs.shape[1]).unsqueeze(0).unsqueeze(0).to(decoder_inputs.device)\n",
    "        decoder_inputs_mask = decoder_inputs.eq(self.pad_idx).unsqueeze(1).unsqueeze(2) + look_ahead_mask\n",
    "\n",
    "        # 编码阶段：将源语言输入映射到嵌入空间\n",
    "        encoder_inputs_embeds = self.src_embedding(encoder_inputs)\n",
    "        encoder_outputs = self.encoder(encoder_inputs_embeds, encoder_inputs_mask)\n",
    "\n",
    "        # 解码阶段：将目标语言输入映射到嵌入空间\n",
    "        decoder_inputs_embeds = self.trg_embedding(decoder_inputs)\n",
    "        decoder_outputs = self.decoder(\n",
    "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
    "            encoder_outputs=encoder_outputs.last_hidden_states,\n",
    "            attn_mask=decoder_inputs_mask,\n",
    "            cross_attn_mask=encoder_inputs_mask,\n",
    "        )\n",
    "\n",
    "        # 将解码器的输出通过线性变换映射到目标语言的词表大小\n",
    "        logits = self.linear(decoder_outputs.last_hidden_states)\n",
    "\n",
    "        return TransformerOutput(\n",
    "            logits=logits,\n",
    "            encoder_last_hidden_states=encoder_outputs.last_hidden_states,\n",
    "            encoder_attn_scores=encoder_outputs.attn_scores,\n",
    "            decoder_last_hidden_states=decoder_outputs.last_hidden_states,\n",
    "            decoder_self_attn_scores=decoder_outputs.self_attn_scores,\n",
    "            decoder_cross_attn_scores=decoder_outputs.cross_attn_scores,\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def infer(self, encoder_inputs, encoder_inputs_mask=None) -> Tensor:\n",
    "        \"\"\"推理：生成目标语言的翻译结果\"\"\"\n",
    "        if encoder_inputs_mask is None:\n",
    "            encoder_inputs_mask = encoder_inputs.eq(self.pad_idx)  # 根据padding生成mask\n",
    "        encoder_inputs_mask = encoder_inputs_mask.unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        # 生成解码器的掩码（自回归）\n",
    "        look_ahead_mask = self.generate_square_subsequent_mask(self.max_length).unsqueeze(0).unsqueeze(0).to(encoder_inputs.device)\n",
    "\n",
    "        # 编码阶段\n",
    "        encoder_inputs_embeds = self.src_embedding(encoder_inputs)\n",
    "        encoder_outputs = self.encoder(encoder_inputs_embeds)\n",
    "\n",
    "        # 解码阶段：生成目标语言翻译\n",
    "        decoder_inputs = torch.Tensor([self.bos_idx] * encoder_inputs.shape[0]).reshape(-1, 1).long().to(device=encoder_inputs.device)\n",
    "        for cur_len in tqdm(range(1, self.max_length + 1)):\n",
    "            decoder_inputs_embeds = self.trg_embedding(decoder_inputs)\n",
    "            decoder_outputs = self.decoder(\n",
    "                decoder_inputs_embeds=decoder_inputs_embeds,\n",
    "                encoder_outputs=encoder_outputs.last_hidden_states,\n",
    "                attn_mask=look_ahead_mask[:, :, :cur_len, :cur_len],\n",
    "            )\n",
    "            logits = self.linear(decoder_outputs.last_hidden_states)\n",
    "            next_token = logits.argmax(dim=-1)[:, -1:]  # 选择下一个最可能的token\n",
    "            decoder_inputs = torch.cat([decoder_inputs, next_token], dim=-1)  # 将token加入解码输入中\n",
    "\n",
    "            # 如果所有样本的解码器输出达到结束标记，则停止解码\n",
    "            if all((decoder_inputs == self.eos_idx).sum(dim=-1) > 0):\n",
    "                break\n",
    "\n",
    "        return TransformerOutput(\n",
    "            preds=decoder_inputs[:, 1:],  # 排除开始标记，返回最终的预测结果\n",
    "            logits=logits,\n",
    "            encoder_last_hidden_states=encoder_outputs.last_hidden_states,\n",
    "            encoder_attn_scores=encoder_outputs.attn_scores,\n",
    "            decoder_last_hidden_states=decoder_outputs.last_hidden_states,\n",
    "            decoder_self_attn_scores=decoder_outputs.self_attn_scores,\n",
    "            decoder_cross_attn_scores=decoder_outputs.cross_attn_scores,\n",
    "        )"
   ],
   "id": "ce5c0ec31017265f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练",
   "id": "7ae5abc23f074b90"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ### 损失函数",
   "id": "a073af9cd4ae401b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CrossEntropyWithPadding:\n",
    "    def __init__(self, config):\n",
    "        # 读取标签平滑参数\n",
    "        self.label_smoothing = config[\"label_smoothing\"]\n",
    "\n",
    "    def __call__(self, logits, labels, padding_mask=None):\n",
    "        bs, seq_len, nc = logits.shape  # 获取批次大小、序列长度和类别数\n",
    "\n",
    "        # 计算交叉熵损失，并应用标签平滑\n",
    "        loss = F.cross_entropy(logits.reshape(bs * seq_len, nc), labels.reshape(-1), reduction='none', label_smoothing=self.label_smoothing)\n",
    "\n",
    "        if padding_mask is None:\n",
    "            loss = loss.mean()  # 无padding时，返回平均损失\n",
    "        else:\n",
    "            # 处理padding掩码，忽略padding部分的损失\n",
    "            padding_mask = 1 - padding_mask.reshape(-1)\n",
    "            loss = torch.mul(loss, padding_mask).sum() / padding_mask.sum()  # 加权损失计算\n",
    "\n",
    "        return loss  # 返回损失值"
   ],
   "id": "ae5ea38f3d17d722",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 学习率衰减",
   "id": "649a38404d094bb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class NoamDecayScheduler:\n",
    "    def __init__(self, config):\n",
    "        # 初始化，获取模型维度和预热步数\n",
    "        self.d_model = config[\"d_model\"]\n",
    "        self.warmup_steps = config[\"warmup_steps\"]\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step += 1\n",
    "        arg1 = step ** (-0.5)  # 步数的衰减因子\n",
    "        arg2 = step * (self.warmup_steps ** (-1.5))  # 预热阶段的衰减因子\n",
    "        arg3 = self.d_model ** (-0.5)  # 模型维度的衰减因子\n",
    "\n",
    "        return arg3 * np.minimum(arg1, arg2)  # 返回衰减后的学习率\n",
    "\n",
    "# 创建一个实例\n",
    "temp_learning_rate_schedule = NoamDecayScheduler({\"d_model\": 512, \"warmup_steps\": 7000})"
   ],
   "id": "21206e2a73781aac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 例子：下面是学习率的设计图\n",
    "plt.plot(temp_learning_rate_schedule(np.arange(0, 40000)))\n",
    "plt.ylabel(\"Leraning rate\")\n",
    "plt.xlabel(\"Train step\")\n",
    "plt.show()"
   ],
   "id": "265b7b712040e2c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 优化器",
   "id": "acc577fe2fa11ec6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.optim import Adam\n",
    "\n",
    "def get_optimizer(model, config):\n",
    "    base_lr = 0.1\n",
    "    beta1 = config[\"beta1\"]  # Adam 的 beta1\n",
    "    beta2 = config[\"beta2\"]  # Adam 的 beta2\n",
    "    eps = config[\"eps\"]\n",
    "\n",
    "    # 初始化Adam优化器\n",
    "    optimizer = Adam(model.parameters(), lr=base_lr, betas=(beta1, beta2), eps=eps)\n",
    "\n",
    "    # 初始化学习率调度器\n",
    "    lr_scheduler = NoamDecayScheduler(config)\n",
    "\n",
    "    # 使用 LambdaLR 调度器调整学习率\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lr_scheduler)\n",
    "\n",
    "    return optimizer, scheduler"
   ],
   "id": "57219a296d6cb65f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Callback",
   "id": "a606a4c9a6ac909d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "class TensorBoardCallback:\n",
    "    def __init__(self, log_dir, flush_secs=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            log_dir (str): dir to write log.\n",
    "            flush_secs (int, optional): write to dsk each flush_secs seconds. Defaults to 10.\n",
    "        \"\"\"\n",
    "        self.writer = SummaryWriter(log_dir=log_dir, flush_secs=flush_secs)\n",
    "\n",
    "    def draw_model(self, model, input_shape):\n",
    "        self.writer.add_graph(model, input_to_model=torch.randn(input_shape))\n",
    "\n",
    "    def add_loss_scalars(self, step, loss, val_loss):\n",
    "        self.writer.add_scalars(\n",
    "            main_tag=\"training/loss\",\n",
    "            tag_scalar_dict={\"loss\": loss, \"val_loss\": val_loss},\n",
    "            global_step=step,\n",
    "            )\n",
    "\n",
    "    def add_acc_scalars(self, step, acc, val_acc):\n",
    "        self.writer.add_scalars(\n",
    "            main_tag=\"training/accuracy\",\n",
    "            tag_scalar_dict={\"accuracy\": acc, \"val_accuracy\": val_acc},\n",
    "            global_step=step,\n",
    "        )\n",
    "\n",
    "    def add_lr_scalars(self, step, learning_rate):\n",
    "        self.writer.add_scalars(\n",
    "            main_tag=\"training/learning_rate\",\n",
    "            tag_scalar_dict={\"learning_rate\": learning_rate},\n",
    "            global_step=step,\n",
    "\n",
    "        )\n",
    "\n",
    "    def __call__(self, step, **kwargs):\n",
    "        # add loss\n",
    "        loss = kwargs.pop(\"loss\", None)\n",
    "        val_loss = kwargs.pop(\"val_loss\", None)\n",
    "        if loss is not None and val_loss is not None:\n",
    "            self.add_loss_scalars(step, loss, val_loss)\n",
    "        # add acc\n",
    "        acc = kwargs.pop(\"acc\", None)\n",
    "        val_acc = kwargs.pop(\"val_acc\", None)\n",
    "        if acc is not None and val_acc is not None:\n",
    "            self.add_acc_scalars(step, acc, val_acc)\n",
    "        # add lr\n",
    "        learning_rate = kwargs.pop(\"lr\", None)\n",
    "        if learning_rate is not None:\n",
    "            self.add_lr_scalars(step, learning_rate)"
   ],
   "id": "54d5e212280338b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SaveCheckpointsCallback:\n",
    "    def __init__(self, save_dir, save_step=5000, save_best_only=True):\n",
    "        \"\"\"\n",
    "        Save checkpoints each save_epoch epoch.\n",
    "        We save checkpoint by epoch in this implementation.\n",
    "        Usually, training scripts with pytorch evaluating model and save checkpoint by step.\n",
    "\n",
    "        Args:\n",
    "            save_dir (str): dir to save checkpoint\n",
    "            save_epoch (int, optional): the frequency to save checkpoint. Defaults to 1.\n",
    "            save_best_only (bool, optional): If True, only save the best model or save each model at every epoch.\n",
    "        \"\"\"\n",
    "        self.save_dir = save_dir\n",
    "        self.save_step = save_step\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_metrics = - np.inf\n",
    "\n",
    "        # mkdir\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            os.mkdir(self.save_dir)\n",
    "\n",
    "    def __call__(self, step, state_dict, metric=None):\n",
    "        if step % self.save_step > 0:\n",
    "            return\n",
    "\n",
    "        if self.save_best_only:\n",
    "            assert metric is not None\n",
    "            if metric >= self.best_metrics:\n",
    "                # save checkpoints\n",
    "                torch.save(state_dict, os.path.join(self.save_dir, \"best.ckpt\"))\n",
    "                # update best metrics\n",
    "                self.best_metrics = metric\n",
    "        else:\n",
    "            torch.save(state_dict, os.path.join(self.save_dir, f\"{step}.ckpt\"))"
   ],
   "id": "671b8f33f2112547",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class EarlyStopCallback:\n",
    "    def __init__(self, patience=5, min_delta=0.01):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            patience (int, optional): Number of epochs with no improvement after which training will be stopped.. Defaults to 5.\n",
    "            min_delta (float, optional): Minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute\n",
    "                change of less than min_delta, will count as no improvement. Defaults to 0.01.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_metric = - np.inf\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, metric):\n",
    "        if metric >= self.best_metric + self.min_delta:\n",
    "            # update best metric\n",
    "            self.best_metric = metric\n",
    "            # reset counter\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "    @property\n",
    "    def early_stop(self):\n",
    "        return self.counter >= self.patience\n"
   ],
   "id": "54d7f60ecbb77331",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training and Evaluation",
   "id": "424244df0f980222"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def evaluating(model, dataloader, loss_fct):\n",
    "    loss_list = []\n",
    "    for batch in dataloader:\n",
    "        encoder_inputs = batch[\"encoder_inputs\"]\n",
    "        encoder_inputs_mask = batch[\"encoder_inputs_mask\"]\n",
    "        decoder_inputs = batch[\"decoder_inputs\"]\n",
    "        decoder_labels = batch[\"decoder_labels\"]\n",
    "        decoder_labels_mask = batch[\"decoder_labels_mask\"]\n",
    "\n",
    "        # 前向计算\n",
    "        outputs = model(\n",
    "            encoder_inputs=encoder_inputs,\n",
    "            decoder_inputs=decoder_inputs,\n",
    "            encoder_inputs_mask=encoder_inputs_mask\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # 计算损失\n",
    "        loss = loss_fct(logits, decoder_labels, padding_mask=decoder_labels_mask)\n",
    "        loss_list.append(loss.cpu().item())\n",
    "\n",
    "    return np.mean(loss_list)  # 返回平均损失"
   ],
   "id": "8c355fdf1c702f4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 训练\n",
    "def training(\n",
    "    model,\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    epoch,\n",
    "    loss_fct,\n",
    "    optimizer,\n",
    "    scheduler=None,\n",
    "    tensorboard_callback=None,\n",
    "    save_ckpt_callback=None,\n",
    "    early_stop_callback=None,\n",
    "    eval_step=500,\n",
    "    ):\n",
    "    record_dict = {\n",
    "        \"train\": [],\n",
    "        \"val\": []\n",
    "    }\n",
    "\n",
    "    val_loss = 0.0\n",
    "    global_step = 1\n",
    "    model.train()\n",
    "    with tqdm(total=epoch * len(train_dl)) as pbar:\n",
    "        for epoch_id in range(epoch):\n",
    "            # training\n",
    "            for batch in train_dl:\n",
    "                encoder_inputs = batch[\"encoder_inputs\"]\n",
    "                encoder_inputs_mask = batch[\"encoder_inputs_mask\"]\n",
    "                decoder_inputs = batch[\"decoder_inputs\"]\n",
    "                decoder_labels = batch[\"decoder_labels\"]\n",
    "                decoder_labels_mask = batch[\"decoder_labels_mask\"]\n",
    "                # 梯度清空\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 前向计算\n",
    "                outputs = model(\n",
    "                    encoder_inputs=encoder_inputs,\n",
    "                    decoder_inputs=decoder_inputs,\n",
    "                    encoder_inputs_mask=encoder_inputs_mask\n",
    "                    )\n",
    "                logits = outputs.logits\n",
    "                loss = loss_fct(logits, decoder_labels, padding_mask=decoder_labels_mask)\n",
    "\n",
    "                # 梯度回传\n",
    "                loss.backward()\n",
    "\n",
    "                # 调整优化器，包括学习率的变动等\n",
    "                optimizer.step()\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step() # 更新学习率\n",
    "\n",
    "                loss = loss.cpu().item()\n",
    "                # record\n",
    "                record_dict[\"train\"].append({\n",
    "                    \"loss\": loss, \"step\": global_step\n",
    "                })\n",
    "\n",
    "                # evaluating\n",
    "                if global_step % eval_step == 0:\n",
    "                    model.eval()\n",
    "                    val_loss = evaluating(model, val_dl, loss_fct)\n",
    "                    record_dict[\"val\"].append({\n",
    "                        \"loss\": val_loss, \"step\": global_step\n",
    "                    })\n",
    "                    model.train()\n",
    "\n",
    "                    # 1. 使用 tensorboard 可视化\n",
    "                    cur_lr = optimizer.param_groups[0][\"lr\"] if scheduler is None else scheduler.get_last_lr()[0]\n",
    "                    if tensorboard_callback is not None:\n",
    "                        tensorboard_callback(\n",
    "                            global_step,\n",
    "                            loss=loss, val_loss=val_loss,\n",
    "                            lr=cur_lr,\n",
    "                            )\n",
    "\n",
    "                    # 2. 保存模型权重 save model checkpoint\n",
    "                    if save_ckpt_callback is not None:\n",
    "                        save_ckpt_callback(global_step, model.state_dict(), metric=-val_loss)\n",
    "\n",
    "                    # 3. 早停 Early Stop\n",
    "                    if early_stop_callback is not None:\n",
    "                        early_stop_callback(-val_loss)\n",
    "                        if early_stop_callback.early_stop:\n",
    "                            print(f\"Early stop at epoch {epoch_id} / global_step {global_step}\")\n",
    "                            return record_dict\n",
    "\n",
    "                # udate step\n",
    "                global_step += 1\n",
    "                pbar.update(1)\n",
    "            pbar.set_postfix({\"epoch\": epoch_id, \"loss\": loss, \"val_loss\": val_loss})\n",
    "\n",
    "    return record_dict"
   ],
   "id": "172f33f11b543d77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Config",
   "id": "bcc0b43b76c9975c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 配置模型的超参数\n",
    "config = {\n",
    "    \"bos_idx\": 1,  # 句子起始标记 (Beginning of Sentence)\n",
    "    \"eos_idx\": 3,  # 句子结束标记 (End of Sentence)\n",
    "    \"pad_idx\": 0,  # 填充标记 (Padding Index)\n",
    "    \"en_vocab_size\": len(en_word2idx),  # 英文词表大小\n",
    "    \"zh_vocab_size\": len(zh_word2idx),  # 中文词表大小\n",
    "    \"max_length\": 128,  # 句子最大长度\n",
    "    \"d_model\": 512,  # Transformer 词向量的维度\n",
    "    \"dim_feedforward\": 2048,  # 前馈神经网络（FFN）的隐藏层大小\n",
    "    \"dropout\": 0.1,  # dropout 率，用于防止过拟合\n",
    "    \"layer_norm_eps\": 1e-6,  # 层归一化 (Layer Normalization) 时的 epsilon，防止除零错误\n",
    "    \"num_heads\": 8,  # 多头注意力机制的头数\n",
    "    \"num_decoder_layers\": 6,  # 解码器层数\n",
    "    \"num_encoder_layers\": 6,  # 编码器层数\n",
    "    \"label_smoothing\": 0.1,  # 交叉熵损失中的标签平滑系数\n",
    "    \"beta1\": 0.9,  # Adam 优化器的 beta1 参数（用于一阶矩估计）\n",
    "    \"beta2\": 0.98,  # Adam 优化器的 beta2 参数（用于二阶矩估计）\n",
    "    \"eps\": 1e-9,  # Adam 优化器的 epsilon，防止除零错误\n",
    "    \"warmup_steps\": 4000,  # 学习率预热步数\n",
    "    \"share_embedding\": False,  # 是否在编码器和解码器之间共享词向量\n",
    "}\n",
    "\n",
    "def get_dl(dataset, batch_size, shuffle=True):\n",
    "    \"\"\"\n",
    "    获取数据加载器 (DataLoader)\n",
    "\n",
    "    参数：\n",
    "    dataset: 训练或验证数据集\n",
    "    batch_size: 批次大小\n",
    "    shuffle: 是否对批次进行随机排序（默认 True）\n",
    "\n",
    "    返回：\n",
    "    DataLoader 对象\n",
    "    \"\"\"\n",
    "    # 使用 Transformer 任务自定义的批次采样器，确保 batch 内的句子长度一致\n",
    "    sampler = TransformerBatchSampler(dataset, batch_size=batch_size, shuffle_batch=shuffle)\n",
    "    # 使用 DataLoader 进行数据加载，collate_fn 用于处理不同长度的句子\n",
    "    sample_dl = DataLoader(dataset, batch_sampler=sampler, collate_fn=partial(collate_fct, en_tokenizer=en_tokenizer, zh_tokenizer=zh_tokenizer))\n",
    "    return sample_dl\n",
    "\n",
    "# 构建训练集和验证集\n",
    "train_ds = LangPairDataset(\"train\", max_length=config[\"max_length\"])  # 训练数据集\n",
    "val_ds = LangPairDataset(\"val\", max_length=config[\"max_length\"])  # 验证数据集\n",
    "\n",
    "# 训练的批次大小\n",
    "batch_size = 2048\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dl = get_dl(train_ds, batch_size=batch_size, shuffle=True)  # 训练数据加载器\n",
    "val_dl = get_dl(val_ds, batch_size=batch_size, shuffle=False)  # 验证数据加载器"
   ],
   "id": "5b30ebeb8dd189ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "# 指定目录\n",
    "save_dir = \"./checkpoints/model_bpe_30000_mini_epoch20_{}\".format(\"share\" if config[\"share_embedding\"] else \"not_share\") \n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 保存路径\n",
    "config_file_path = os.path.join(save_dir, \"Config.txt\")\n",
    "\n",
    "# 将 config 字典写入文件\n",
    "with open(config_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(f\"Config has been saved to {config_file_path}\")"
   ],
   "id": "797a8e1aaeea3802",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#计算模型参数量\n",
    "model = TransformerModel(config)\n",
    "print(f\"模型参数量: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ],
   "id": "d054d3344121700a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "epoch = 20\n",
    "\n",
    "# 初始化模型\n",
    "model = TransformerModel(config)\n",
    "\n",
    "# 定义损失函数，采用交叉熵损失\n",
    "loss_fct = CrossEntropyWithPadding(config)\n",
    "\n",
    "# 定义优化器和学习率调度器，采用 Adam 优化器\n",
    "optimizer, scheduler = get_optimizer(model, config)\n",
    "\n",
    "# 创建 tensorboard 可视化目录\n",
    "if not os.path.exists(\"runs\"):\n",
    "    os.mkdir(\"runs\")\n",
    "\n",
    "# exp_name \n",
    "exp_name = \"model_bpe_30000_mini_epoch20_{}\".format(\"share\" if config[\"share_embedding\"] else \"not_share\")\n",
    "tensorboard_callback = TensorBoardCallback(f\"runs/{exp_name}\")\n",
    "\n",
    "# 创建保存检查点的目录\n",
    "if not os.path.exists(\"checkpoints\"):\n",
    "    os.makedirs(\"checkpoints\")\n",
    "save_ckpt_callback = SaveCheckpointsCallback(f\"checkpoints/{exp_name}\", save_step=500, save_best_only=True)\n",
    "\n",
    "# 早停机制\n",
    "early_stop_callback = EarlyStopCallback(patience=8)\n",
    "\n",
    "# 将模型转移到设备\n",
    "model = model.to(device)"
   ],
   "id": "9ca2b7400ff45b3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 开始训练",
   "id": "669922b10120027"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T05:41:10.134356Z",
     "start_time": "2025-02-26T05:21:35.619666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "record = training(\n",
    "    model,\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    epoch,\n",
    "    loss_fct,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    tensorboard_callback=None,\n",
    "    save_ckpt_callback=save_ckpt_callback,\n",
    "    early_stop_callback=early_stop_callback,\n",
    "    eval_step=500\n",
    "    )"
   ],
   "id": "99bfe77a2ff190e7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13700/13700 [19:34<00:00, 11.66it/s, epoch=19, loss=4.53, val_loss=6.19]\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ### 损失率折线图",
   "id": "f0f3cfe01971f620"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T05:41:10.378703Z",
     "start_time": "2025-02-26T05:41:10.136358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_losses = [item['loss'] for item in record['train']]\n",
    "train_steps = [item['step'] for item in record['train']]\n",
    "val_losses = [item['loss'] for item in record['val']]\n",
    "val_steps = [item['step'] for item in record['val']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_steps, train_losses, label='Training Loss')\n",
    "plt.plot(val_steps, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "8347bcbc76e528a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 推理",
   "id": "39580a6bee41fe05"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 加载模型",
   "id": "fd5ded5540042285"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T05:41:11.917208Z",
     "start_time": "2025-02-26T05:41:10.379706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "state_dict = torch.load(f\"./checkpoints/{exp_name}/best.ckpt\", map_location=\"cpu\", weights_only=True)\n",
    "\n",
    "# 加载 Transformer 模型\n",
    "model = TransformerModel(config)  # 初始化 Transformer 模型\n",
    "model.load_state_dict(state_dict)  # 加载预训练模型的参数"
   ],
   "id": "563c9ac7eda78ee6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 计算 BLEU 评分",
   "id": "37426f5b72478607"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T05:41:34.396649Z",
     "start_time": "2025-02-26T05:41:11.919210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 定义损失函数（交叉熵损失，带有标签平滑）\n",
    "loss_fct = CrossEntropyWithPadding(config)\n",
    "\n",
    "# 加载测试数据集\n",
    "test_ds = LangPairDataset(\"test\", max_length=128, data_dir=f\"./{dataset_path}\")  # 测试数据集\n",
    "test_dl = DataLoader(test_ds, batch_size=1, collate_fn=partial(collate_fct, en_tokenizer=en_tokenizer, zh_tokenizer=zh_tokenizer))  # 数据加载器\n",
    "\n",
    "# 迁移模型到计算设备（CPU/GPU）\n",
    "model = model.to(device)\n",
    "model.eval()  # 设置模型为评估模式，防止 dropout 或 batchnorm 影响推理\n",
    "\n",
    "# 创建平滑函数实例\n",
    "smoothing_function = SmoothingFunction().method1  # 使用method1平滑\n",
    "\n",
    "# 定义数据收集字典\n",
    "collect = {}  # 用于存储测试集中的样本及其损失\n",
    "loss_collect = []  # 用于收集所有样本的损失\n",
    "\n",
    "predictions = []  # 存储所有预测结果\n",
    "answers = []  # 存储所有真实标签\n",
    "bleu1_scores = []  # 存储 BLEU-1 评分\n",
    "bleu2_scores = []  # 存储 BLEU-2 评分\n",
    "bleu3_scores = []  # 存储 BLEU-3 评分\n",
    "bleu4_scores = []  # 存储 BLEU-4 评分\n",
    "\n",
    "# 遍历测试集\n",
    "for idx, batch in tqdm(enumerate(test_dl), total=len(test_dl), desc=\"Evaluating\", unit=\"batch\"):\n",
    "    encoder_inputs = batch[\"encoder_inputs\"]  # 编码器输入（源语言）\n",
    "    encoder_inputs_mask = batch[\"encoder_inputs_mask\"]  # 源输入的填充掩码\n",
    "    decoder_inputs = batch[\"decoder_inputs\"]  # 解码器输入（目标语言）\n",
    "    decoder_labels = batch[\"decoder_labels\"]  # 目标真实标签（用于计算损失）\n",
    "\n",
    "    # 进行前向传播，获取 Transformer 输出\n",
    "    outputs = model(\n",
    "        encoder_inputs=encoder_inputs,\n",
    "        decoder_inputs=decoder_inputs,\n",
    "        encoder_inputs_mask=encoder_inputs_mask\n",
    "    )\n",
    "\n",
    "    # 计算交叉熵损失\n",
    "    loss = loss_fct(outputs.logits, decoder_labels)\n",
    "\n",
    "    # 获取预测结果：取每个时间步上最大概率的词索引\n",
    "    preds = outputs.logits.argmax(dim=-1)  # 预测序列形状为 [1, seq_len]\n",
    "\n",
    "    # 将预测索引转换为实际的文本句子\n",
    "    preds = zh_tokenizer.decode(preds.cpu().numpy())  # ['预测句子']\n",
    "\n",
    "    # 将真实标签转换为文本句子\n",
    "    decoder_labels = zh_tokenizer.decode(decoder_labels.cpu().numpy())  # ['标签句子']\n",
    "\n",
    "    # 计算不同n-gram的BLEU评分\n",
    "    bleu1 = sentence_bleu([decoder_labels[0].split()], preds[0].split(), weights=(1, 0, 0, 0), smoothing_function=smoothing_function)\n",
    "    bleu2 = sentence_bleu([decoder_labels[0].split()], preds[0].split(), weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing_function)\n",
    "    bleu3 = sentence_bleu([decoder_labels[0].split()], preds[0].split(), weights=(0.33, 0.33, 0.33, 0), smoothing_function=smoothing_function)\n",
    "    bleu4 = sentence_bleu([decoder_labels[0].split()], preds[0].split(), weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing_function)\n",
    "\n",
    "    bleu1_scores.append(bleu1)  # 存储 BLEU-1 分数\n",
    "    bleu2_scores.append(bleu2)  # 存储 BLEU-2 分数\n",
    "    bleu3_scores.append(bleu3)  # 存储 BLEU-3 分数\n",
    "    bleu4_scores.append(bleu4)  # 存储 BLEU-4 分数\n",
    "\n",
    "    # 记录样本信息，包括损失、输入、目标、预测\n",
    "    collect[idx] = {\n",
    "        \"loss\": loss.item(),  # 当前样本的损失\n",
    "        \"src_inputs\": encoder_inputs,  # 源语言输入\n",
    "        \"trg_inputs\": decoder_inputs,  # 目标语言输入\n",
    "        \"mask\": encoder_inputs_mask,  # 源语言的填充掩码\n",
    "        \"trg_labels\": decoder_labels,  # 真实目标文本\n",
    "        \"preds\": preds  # 预测文本\n",
    "    }\n",
    "\n",
    "    # 记录损失\n",
    "    loss_collect.append(loss.item())\n",
    "\n",
    "# 按照损失大小对收集的数据进行排序（从低到高）\n",
    "collect = sorted(collect.items(), key=lambda x: x[1][\"loss\"])\n",
    "\n",
    "# 输出测试集平均损失\n",
    "print(f\"testing loss: {np.array(loss_collect).mean()}\")\n",
    "\n",
    "# 输出各个n-gram BLEU评分的平均值\n",
    "print(f\"Average BLEU-1 score: {sum(bleu1_scores) / len(bleu1_scores)}\")\n",
    "print(f\"Average BLEU-2 score: {sum(bleu2_scores) / len(bleu2_scores)}\")\n",
    "print(f\"Average BLEU-3 score: {sum(bleu3_scores) / len(bleu3_scores)}\")\n",
    "print(f\"Average BLEU-4 score: {sum(bleu4_scores) / len(bleu4_scores)}\")"
   ],
   "id": "6c3a34b0b93a3f6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save cache to train_data_size_50000\\.cache\\de2en_test_128.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1052/1052 [00:21<00:00, 48.63batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing loss: 5.814124622725715\n",
      "Average BLEU-1 score: 0.23876087788742656\n",
      "Average BLEU-2 score: 0.10754318476764056\n",
      "Average BLEU-3 score: 0.06786188950275449\n",
      "Average BLEU-4 score: 0.04602952072648175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Translating",
   "id": "4935fbd334a4b7a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T05:43:47.245852Z",
     "start_time": "2025-02-26T05:43:44.695323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from sacremoses import MosesDetokenizer, MosesTokenizer\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import matplotlib\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self, model, en_tokenizer, zh_tokenizer, dataset_path=\"./train_data_size_50000\"):\n",
    "        \"\"\"\n",
    "        初始化翻译器类，包含 BPE 处理、分词、去标记化和模型推理功能。\n",
    "        \"\"\"\n",
    "        self.dataset_path = Path(dataset_path)\n",
    "        \n",
    "        # 英文和中文的 BPE 规则文件\n",
    "        self.en_bpe_rules = self.dataset_path / \"bpe.en.30000\"\n",
    "        self.zh_bpe_rules = self.dataset_path / \"bpe.zh.30000\"\n",
    "        \n",
    "        # 英文和中文的词汇表文件\n",
    "        self.en_vocab = self.dataset_path / \"en.vocab\"\n",
    "        self.zh_vocab = self.dataset_path / \"zh.vocab\"\n",
    "\n",
    "        # 初始化 Moses 分词器和去标记化器\n",
    "        self.mose_tokenizer = MosesTokenizer(lang=\"en\")  # 英文分词器\n",
    "        self.mose_detokenizer = MosesDetokenizer(lang=\"zh\")  # 中文去标记化器\n",
    "\n",
    "        # 设置模型和评估模式\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "        # 设置英文和中文的 tokenizer\n",
    "        self.en_tokenizer = en_tokenizer\n",
    "        self.zh_tokenizer = zh_tokenizer\n",
    "        \n",
    "        # 正则模式，用于去除 BPE 标记\n",
    "        self.pattern = re.compile(r'(@@ )|(@@ ?$)')\n",
    "\n",
    "    def apply_bpe(self, input_file, output_file, bpe_rules, vocab_file):\n",
    "        \"\"\"\n",
    "        使用 subword-nmt 的 apply-bpe 命令对文件进行 BPE 分词。\n",
    "        \n",
    "        :param input_file: 输入文件路径\n",
    "        :param output_file: 输出文件路径\n",
    "        :param bpe_rules: BPE 规则文件路径\n",
    "        :param vocab_file: 词汇表文件路径\n",
    "        \"\"\"\n",
    "        try:\n",
    "            subprocess.run([\n",
    "                \"subword-nmt\", \"apply-bpe\",\n",
    "                \"-c\", str(bpe_rules),\n",
    "                \"--vocabulary\", str(vocab_file),\n",
    "                \"--vocabulary-threshold\", \"50\",\n",
    "                \"-i\", str(input_file),\n",
    "                \"-o\", str(output_file)\n",
    "            ], check=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            raise RuntimeError(f\"Failed to apply BPE: {e}\")\n",
    "\n",
    "    def draw_attention_map(self, attn_scores, cross_attn_scores, src_words_list, trg_words_list):\n",
    "        \"\"\"\n",
    "        绘制 Transformer 模型的注意力（Attention）热力图，包括自注意力和交叉注意力。\n",
    "        \"\"\"\n",
    "        # 设置中文字体\n",
    "        matplotlib.rcParams['font.sans-serif'] = ['SimHei']  # 指定黑体\n",
    "        matplotlib.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "        \n",
    "        # 验证输入张量的形状\n",
    "        assert len(attn_scores.shape) == 3, f\"attn_scores 形状应为 [num_heads, trg_len, trg_len]，但得到了 {attn_scores.shape}\"\n",
    "        attn_scores = attn_scores[:, :len(trg_words_list), :len(trg_words_list)]  # 截取目标序列长度\n",
    "        assert len(cross_attn_scores.shape) == 3, f\"cross_attn_scores 形状应为 [num_heads, trg_len, src_len]，但得到了 {cross_attn_scores.shape}\"\n",
    "        cross_attn_scores = cross_attn_scores[:, :len(trg_words_list), :len(src_words_list)]  # 截取源序列长度\n",
    "\n",
    "        num_heads, trg_len, src_len = cross_attn_scores.shape\n",
    "\n",
    "        fig = plt.figure(figsize=(12, 8), constrained_layout=True)\n",
    "        grid = fig.add_gridspec(trg_len, trg_len + src_len, wspace=0.1, hspace=0.1)\n",
    "\n",
    "\n",
    "        # 绘制自注意力热力图\n",
    "        self_map = fig.add_subplot(grid[:, :trg_len])\n",
    "        self_map.matshow(attn_scores.mean(dim=0), cmap='viridis')  # 平均值作为热力图\n",
    "        self_map.set_yticks(range(trg_len), trg_words_list, fontsize=10)\n",
    "        self_map.set_xticks(range(trg_len), [\"[BOS]\"] + trg_words_list[:-1], rotation=90)\n",
    "\n",
    "        # 绘制交叉注意力热力图\n",
    "        cross_map = fig.add_subplot(grid[:, trg_len:])\n",
    "        cross_map.matshow(cross_attn_scores.mean(dim=0), cmap='viridis')\n",
    "        cross_map.set_yticks(range(trg_len), [])\n",
    "        cross_map.set_xticks(range(src_len), src_words_list, rotation=90)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def __call__(self, sentence_list, heads_list=None, layer_idx=-1):\n",
    "        \"\"\"\n",
    "        执行翻译任务，并可选地绘制注意力热力图。\n",
    "        \"\"\"\n",
    "        # 英文句子预处理\n",
    "        sentence_list = [\" \".join(self.mose_tokenizer.tokenize(s.lower())) for s in sentence_list]\n",
    "        print(sentence_list)\n",
    "        \n",
    "        # 将句子列表写入临时文件\n",
    "        temp_input_file = self.dataset_path / \"temp_input.txt\"\n",
    "        temp_output_file = self.dataset_path / \"temp_output.bpe\"\n",
    "        \n",
    "        # 写入英文句子\n",
    "        with open(temp_input_file, \"w\", encoding=\"utf8\") as f:\n",
    "            f.write(\"\\n\".join(sentence_list))\n",
    "\n",
    "        # 对英文句子进行 BPE 分词\n",
    "        self.apply_bpe(temp_input_file, temp_output_file, self.en_bpe_rules, self.en_vocab)\n",
    "\n",
    "        # 读取 BPE 分词后的结果\n",
    "        with open(temp_output_file, \"r\", encoding=\"utf8\") as f:\n",
    "            en_tokens_list = [line.strip().split() for line in f]\n",
    "        print(\"English tokens1:\", en_tokens_list)\n",
    "\n",
    "        # 使用英文tokenizer处理输入\n",
    "        encoder_input, attn_mask = self.en_tokenizer.encode(en_tokens_list, add_bos=True, add_eos=True, return_mask=True)\n",
    "        print(\"English tokens2:\", encoder_input) \n",
    "        print(\"Attention mask:\", attn_mask)\n",
    "        \n",
    "        encoder_input = torch.Tensor(encoder_input).to(dtype=torch.int64)\n",
    "        print(\"Encoder input:\", encoder_input)\n",
    "       \n",
    "        # 执行模型推理\n",
    "        outputs = self.model.infer(encoder_inputs=encoder_input, encoder_inputs_mask=attn_mask)\n",
    "\n",
    "        preds = outputs.preds.numpy()\n",
    "        print(\"Predictions:\", preds)\n",
    "\n",
    "        # 获取模型的注意力分数\n",
    "        attn_scores = outputs.decoder_self_attn_scores[layer_idx]  # 自注意力\n",
    "        cross_attn_scores = outputs.decoder_cross_attn_scores[layer_idx]  # 交叉注意力\n",
    "\n",
    "        # 使用中文tokenizer解码输出\n",
    "        trg_decoded = self.zh_tokenizer.decode(preds, split=True, remove_eos=False, remove_bos=False, remove_pad=False)\n",
    "        # 使用英文tokenizer解码输入\n",
    "        src_decoded = self.en_tokenizer.decode(encoder_input.numpy(), split=True, remove_bos=False, remove_eos=False)\n",
    "\n",
    "        # 绘制注意力图\n",
    "        for attn_score, cross_attn_score, src, trg in zip(attn_scores, cross_attn_scores, src_decoded, trg_decoded):\n",
    "            self.draw_attention_map(attn_score, cross_attn_score, src, trg)\n",
    "\n",
    "        # 返回翻译结果，去除 BPE 标记\n",
    "        return [self.mose_detokenizer.tokenize(self.pattern.sub(\"\", s).split()) for s in self.zh_tokenizer.decode(preds)]\n",
    "\n",
    "\n",
    "# 示例输入句子列表（英文）\n",
    "sentence_list = [\"How are you doing today?\"]\n",
    "# \"In table 7, the Committee notes a marked difference in the figures for consultants in the International Tribunal for the Former Yugoslavia and the International Criminal Tribunal for Rwanda.\"\n",
    "# \"He stated that peacekeeping operations should focus on prevention rather than reaction to conflicts.\"\n",
    "# \"Ms. Maria emphasized that financial resources should be directed to regions facing economic challenges, particularly those with limited resources.\"\n",
    "# \"The secretary-general of the organization could provide support for the implementation of measures between parties, working towards security and assistance for children in need.\"\n",
    "# \"I am an old man who is very tired.\",\n",
    "# \"I have a new car, and it is very fast.\"\n",
    "\n",
    "# 加载模型并进行推理\n",
    "model = TransformerModel(config)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# 假设 en_tokenizer 和 zh_tokenizer 已经初始化\n",
    "translator = Translator(model.cpu(), en_tokenizer, zh_tokenizer)\n",
    "\n",
    "# 执行翻译并绘制热力图\n",
    "translated_sentences = translator(sentence_list, layer_idx=-1)\n",
    "\n",
    "# 输出翻译结果\n",
    "for sentence in translated_sentences:\n",
    "    print(\"Translated sentence:\", sentence)"
   ],
   "id": "f0d6fd1343aa89eb",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TransformerModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 160\u001B[0m\n\u001B[0;32m    151\u001B[0m sentence_list \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHow are you doing today?\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    152\u001B[0m \u001B[38;5;66;03m# \"In table 7, the Committee notes a marked difference in the figures for consultants in the International Tribunal for the Former Yugoslavia and the International Criminal Tribunal for Rwanda.\"\u001B[39;00m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;66;03m# \"He stated that peacekeeping operations should focus on prevention rather than reaction to conflicts.\"\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;66;03m# \"Ms. Maria emphasized that financial resources should be directed to regions facing economic challenges, particularly those with limited resources.\"\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    158\u001B[0m \n\u001B[0;32m    159\u001B[0m \u001B[38;5;66;03m# 加载模型并进行推理\u001B[39;00m\n\u001B[1;32m--> 160\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mTransformerModel\u001B[49m(config)\n\u001B[0;32m    161\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(state_dict)\n\u001B[0;32m    163\u001B[0m \u001B[38;5;66;03m# 假设 en_tokenizer 和 zh_tokenizer 已经初始化\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'TransformerModel' is not defined"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
