{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741005625510,
     "user_tz": -480,
     "elapsed": 2,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:46.105178Z",
     "start_time": "2025-03-06T07:17:41.109205Z"
    }
   },
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# 让图形在 Jupyter Notebook 中内嵌显示\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "7ea0c290f8099f6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1741005625520,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     },
     "user_tz": -480
    },
    "id": "7ea0c290f8099f6a",
    "outputId": "b820a8d2-e877-49d0-f7c4-6078f27aad89",
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:46.183974Z",
     "start_time": "2025-03-06T07:17:46.106179Z"
    }
   },
   "source": [
    "# 打印当前 Python 版本信息\n",
    "print(sys.version_info)\n",
    "\n",
    "# 打印使用库的版本信息\n",
    "for module in mpl, np, pd, sklearn, torch :\n",
    "    print(module.__name__, module.__version__)\n",
    "\n",
    "# 设置 PyTorch 计算设备\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "# 设置随机种子，以保证实验的可复现性\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=12, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.10.0\n",
      "numpy 2.0.2\n",
      "pandas 2.2.3\n",
      "sklearn 1.6.0\n",
      "torch 2.5.1+cu118\n",
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "9baf1472469ce7aa",
   "metadata": {
    "id": "9baf1472469ce7aa"
   },
   "source": [
    "## DataLoader准备\n",
    "### LangPairDataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "4892cd122f3d3f38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9010,
     "status": "ok",
     "timestamp": 1741005635028,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     },
     "user_tz": -480
    },
    "id": "4892cd122f3d3f38",
    "outputId": "d0fe6a9f-c95a-4c71-9b36-15dd1b78b0af",
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:48.221363Z",
     "start_time": "2025-03-06T07:17:46.198402Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "dataset_path = \"./train_data_size_1000000_zh2en\"\n",
    "\n",
    "class LangPairDataset(Dataset):\n",
    "    \"\"\"\n",
    "    加载和处理双语数据集，并支持数据缓存。\n",
    "    \"\"\"\n",
    "    def __init__(self, mode=\"train\", max_length=128, overwrite_cache=False, data_dir=dataset_path):\n",
    "        \"\"\"\n",
    "        初始化数据集。\n",
    "        :param mode: 数据集模式（\"train\" 或 \"val\"）\n",
    "        :param max_length: 句子最大长度，超过则过滤\n",
    "        :param overwrite_cache: 是否覆盖缓存，默认为 False\n",
    "        :param data_dir: 数据目录\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)  # 数据存储路径\n",
    "        cache_path = self.data_dir / \".cache\" / f\"de2en_{mode}_{max_length}.npy\"  # 缓存路径\n",
    "\n",
    "        if overwrite_cache or not cache_path.exists():  # 覆盖缓存或缓存不存在时重新处理\n",
    "            cache_path.parent.mkdir(parents=True, exist_ok=True)  # 创建缓存目录\n",
    "\n",
    "            # 读取源语言和目标语言文件\n",
    "            with open(self.data_dir / f\"{mode}_src.bpe\", \"r\", encoding=\"utf8\") as file:\n",
    "                self.src = file.readlines()\n",
    "\n",
    "            with open(self.data_dir / f\"{mode}_trg.bpe\", \"r\", encoding=\"utf8\") as file:\n",
    "                self.trg = file.readlines()\n",
    "\n",
    "            filtered_src, filtered_trg = [], []  # 存放过滤后的句子\n",
    "\n",
    "            # 过滤句子长度\n",
    "            for src, trg in zip(self.src, self.trg):\n",
    "                if len(src) <= max_length and len(trg) <= max_length:\n",
    "                    filtered_src.append(src.strip())  # 去除首尾空格\n",
    "                    filtered_trg.append(trg.strip())\n",
    "\n",
    "            # 保存为 NumPy 数组并缓存\n",
    "            np.save(cache_path, {\"src\": np.array(filtered_src), \"trg\": np.array(filtered_trg)}, allow_pickle=True)\n",
    "            print(f\"save cache to {cache_path}\")\n",
    "\n",
    "        else:  # 加载已有缓存\n",
    "            cache_dict = np.load(cache_path, allow_pickle=True).item()\n",
    "            print(f\"load {mode} dataset from {cache_path}\")\n",
    "            filtered_src = cache_dict[\"src\"]\n",
    "            filtered_trg = cache_dict[\"trg\"]\n",
    "\n",
    "        self.src = filtered_src  # 源语言数据\n",
    "        self.trg = filtered_trg  # 目标语言数据\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        获取指定索引的源语言和目标语言句子。\n",
    "        \"\"\"\n",
    "        return self.src[index], self.trg[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集大小。\n",
    "        \"\"\"\n",
    "        return len(self.src)\n",
    "\n",
    "# # 创建训练集和验证集对象\n",
    "# train_ds = LangPairDataset(\"train\")\n",
    "# val_ds = LangPairDataset(\"val\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save cache to train_data_size_1000000_zh2en\\.cache\\de2en_train_128.npy\n",
      "save cache to train_data_size_1000000_zh2en\\.cache\\de2en_val_128.npy\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "9902f9c937b68aaf",
   "metadata": {
    "id": "9902f9c937b68aaf"
   },
   "source": [
    " ### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "6320edf9d082e46e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "5ad4c47414d349c1b44fb38afc8449a9",
      "a7e755097ad94a27baa4908d85564fe3",
      "c336ff919ad84c06b4d435af8812da34",
      "db072193241b4176abd7dff003ad4c22",
      "60dc9410aadc4e98a65b2621fc2bd294",
      "e8a5c441580f4fbba993d85e94ab7f25",
      "232d53940b5844d7a40ad03c7ece7459",
      "b83a47e3df014d6aa927559f0240d248",
      "8739091f49cb45a3a32f4e6610337024",
      "c301ed4cc6b642c5be5d5d4f03b5696d",
      "cdbcd22293aa46318e72ad3eedf979ab",
      "9637c960540e482a91130e54e64d4a32",
      "047bb5c224b94380b292ba1b133e0417",
      "7a8b3dc358154d25aabfa8ad218a19bc",
      "3a17919d1d854783940dbf23d7061f36",
      "89a51a19525649308a9fc3d068ba4319",
      "ceb3853559e548dc85979b470b4e6143",
      "da9d413568a54d0d8dc97f7db1fcaf16",
      "9d0364127f6b48d4aac7adfc68b21752",
      "65093a24b53041efb05248534b2f4e3e",
      "33d480e964954516a0d3a0767204e79b",
      "5eae7f34d8a744aebdeada57727b0361"
     ]
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1741005635344,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     },
     "user_tz": -480
    },
    "id": "6320edf9d082e46e",
    "outputId": "116edd6c-b1c3-4bdf-8470-a6dc70794315",
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:48.357127Z",
     "start_time": "2025-03-06T07:17:48.225333Z"
    }
   },
   "source": [
    "# 构建英文和中文的word2idx和idx2word字典\n",
    "en_word2idx = {\n",
    "    \"[PAD]\": 0,\n",
    "    \"[BOS]\": 1,\n",
    "    \"[UNK]\": 2,\n",
    "    \"[EOS]\": 3,\n",
    "}\n",
    "zh_word2idx = {\n",
    "    \"[PAD]\": 0,\n",
    "    \"[BOS]\": 1,\n",
    "    \"[UNK]\": 2,\n",
    "    \"[EOS]\": 3,\n",
    "}\n",
    "\n",
    "# 反向索引\n",
    "en_idx2word = {value: key for key, value in en_word2idx.items()}\n",
    "zh_idx2word = {value: key for key, value in zh_word2idx.items()}\n",
    "\n",
    "# 分别加载英文和中文词表\n",
    "en_index = len(en_idx2word)\n",
    "zh_index = len(zh_idx2word)\n",
    "threshold = 1\n",
    "\n",
    "# 读取英文词表\n",
    "with open(f\"{dataset_path}/en.vocab\", \"r\", encoding=\"utf8\") as file:\n",
    "    for line in tqdm(file.readlines()):\n",
    "        token, counts = line.strip().split()\n",
    "        if int(counts) >= threshold:\n",
    "            en_word2idx[token] = en_index\n",
    "            en_idx2word[en_index] = token\n",
    "            en_index += 1\n",
    "\n",
    "# 读取中文词表\n",
    "with open(f\"{dataset_path}/zh.vocab\", \"r\", encoding=\"utf8\") as file:\n",
    "    for line in tqdm(file.readlines()):\n",
    "        token, counts = line.strip().split()\n",
    "        if int(counts) >= threshold:\n",
    "            zh_word2idx[token] = zh_index\n",
    "            zh_idx2word[zh_index] = token\n",
    "            zh_index += 1"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/47609 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44415eb55d7c4705a32bc33b793212eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/54986 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efa18887152746d998d5021dd07c1fdb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "ff0473d08da12b51",
   "metadata": {
    "id": "ff0473d08da12b51",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741005635524,
     "user_tz": -480,
     "elapsed": 179,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:48.365131Z",
     "start_time": "2025-03-06T07:17:48.358134Z"
    }
   },
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, word2idx, idx2word, max_length=128, pad_idx=0, bos_idx=1, eos_idx=3, unk_idx=2):\n",
    "        \"\"\"\n",
    "        初始化 Tokenizer。\n",
    "        :param word2idx: 单词到索引的映射\n",
    "        :param idx2word: 索引到单词的映射\n",
    "        :param max_length: 最大句子长度，超出则截断\n",
    "        :param pad_idx: 填充 token 索引\n",
    "        :param bos_idx: 句子起始 token 索引\n",
    "        :param eos_idx: 句子结束 token 索引\n",
    "        :param unk_idx: 未知单词索引\n",
    "        \"\"\"\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.max_length = max_length\n",
    "        self.pad_idx = pad_idx\n",
    "        self.bos_idx = bos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.unk_idx = unk_idx\n",
    "\n",
    "    def encode(self, text_list, padding_first=False, add_bos=True, add_eos=True, return_mask=False):\n",
    "        \"\"\"\n",
    "        将文本列表编码为索引列表。\n",
    "        :param text_list: 文本列表，每个元素是一个单词列表\n",
    "        :param padding_first: 是否将 [PAD] 填充到句首\n",
    "        :param add_bos: 是否添加 [BOS] 起始符号\n",
    "        :param add_eos: 是否添加 [EOS] 结束符号\n",
    "        :param return_mask: 是否返回 mask\n",
    "        :return: 编码后的 input_ids 或 (input_ids, masks)\n",
    "        \"\"\"\n",
    "        max_length = min(self.max_length, add_eos + add_bos + max([len(text) for text in text_list]))\n",
    "        indices_list = []\n",
    "\n",
    "        for text in text_list:\n",
    "            indices = [self.word2idx.get(word, self.unk_idx) for word in text[:max_length - add_bos - add_eos]]\n",
    "            if add_bos: indices = [self.bos_idx] + indices\n",
    "            if add_eos: indices = indices + [self.eos_idx]\n",
    "\n",
    "            # 填充到 max_length\n",
    "            if padding_first:\n",
    "                indices = [self.pad_idx] * (max_length - len(indices)) + indices\n",
    "            else:\n",
    "                indices = indices + [self.pad_idx] * (max_length - len(indices))\n",
    "\n",
    "            indices_list.append(indices)\n",
    "\n",
    "        input_ids = torch.tensor(indices_list) # 转换为 tensor\n",
    "        masks = (input_ids == self.pad_idx).to(dtype=torch.int64)  # 生成 mask，标记 padding 部分\n",
    "\n",
    "        return input_ids if not return_mask else (input_ids, masks)\n",
    "\n",
    "    def decode(self, indices_list, remove_bos=True, remove_eos=True, remove_pad=True, split=False):\n",
    "        \"\"\"\n",
    "        解码索引列表为文本列表。\n",
    "        :param indices_list: 索引列表\n",
    "        :param remove_bos: 是否移除 [BOS]\n",
    "        :param remove_eos: 是否移除 [EOS]\n",
    "        :param remove_pad: 是否移除 [PAD]\n",
    "        :param split: 是否返回分词列表\n",
    "        :return: 解码后的文本列表\n",
    "        \"\"\"\n",
    "        text_list = []\n",
    "\n",
    "        for indices in indices_list:\n",
    "            text = []\n",
    "            for index in indices:\n",
    "                word = self.idx2word.get(index, \"[UNK]\")  # 获取单词\n",
    "                if remove_bos and word == \"[BOS]\": continue\n",
    "                if remove_eos and word == \"[EOS]\": break\n",
    "                if remove_pad and word == \"[PAD]\": break\n",
    "                text.append(word)\n",
    "\n",
    "            text_list.append(\" \".join(text) if not split else text)\n",
    "\n",
    "        return text_list"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "d020a4b0bcfeb51c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1741005635530,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     },
     "user_tz": -480
    },
    "id": "d020a4b0bcfeb51c",
    "outputId": "a446d5fe-4235-49e6-abcf-3a59d52b4311",
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:48.369851Z",
     "start_time": "2025-03-06T07:17:48.366133Z"
    }
   },
   "source": [
    "# 创建英文和中文的tokenizer\n",
    "en_tokenizer = Tokenizer(word2idx=en_word2idx, idx2word=en_idx2word)\n",
    "zh_tokenizer = Tokenizer(word2idx=zh_word2idx, idx2word=zh_idx2word)\n",
    "\n",
    "# 输出词表大小\n",
    "en_vocab_size = len(en_word2idx)\n",
    "zh_vocab_size = len(zh_word2idx)\n",
    "print(\"en_vocab_size: {}\".format(en_vocab_size))  # 打印英文词表大小\n",
    "print(\"zh_vocab_size: {}\".format(zh_vocab_size))  # 打印中文词表大小"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_vocab_size: 47613\n",
      "zh_vocab_size: 54990\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "b570d392dee27856",
   "metadata": {
    "id": "b570d392dee27856"
   },
   "source": [
    "### Transformer Batch Sampler"
   ]
  },
  {
   "cell_type": "code",
   "id": "5c67080f63578e89",
   "metadata": {
    "id": "5c67080f63578e89",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741005635532,
     "user_tz": -480,
     "elapsed": 1,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:48.375728Z",
     "start_time": "2025-03-06T07:17:48.370853Z"
    }
   },
   "source": [
    "class SampleInfo:\n",
    "    def __init__(self, i, lens):\n",
    "        \"\"\"\n",
    "        记录文本对的序号和长度信息。\n",
    "\n",
    "        :param i: 文本对的序号。\n",
    "        :param lens: 文本对的长度，包含源语言和目标语言的长度。\n",
    "        \"\"\"\n",
    "        self.i = i\n",
    "        # 加一是为了考虑填充的特殊词元，lens[0] 和 lens[1] 分别表示源语言和目标语言的长度\n",
    "        self.max_len = max(lens[0], lens[1]) + 1\n",
    "        self.src_len = lens[0] + 1\n",
    "        self.trg_len = lens[1] + 1\n",
    "\n",
    "\n",
    "class TokenBatchCreator:\n",
    "    def __init__(self, batch_size):\n",
    "        \"\"\"\n",
    "        根据词元数目限制批量大小，并初始化批量存储结构。\n",
    "\n",
    "        :param batch_size: 批量的最大大小。\n",
    "        \"\"\"\n",
    "        self._batch = []  # 当前处理的样本\n",
    "        self.max_len = -1  # 当前批量的最大长度\n",
    "        self._batch_size = batch_size  # 批量大小限制\n",
    "\n",
    "    def append(self, info: SampleInfo):\n",
    "        \"\"\"\n",
    "        将样本信息添加到批量中。如果当前批量大小超过限制，则返回当前批量并创建新批量。\n",
    "\n",
    "        :param info: 包含文本对长度信息的 SampleInfo 对象。\n",
    "        :return: 当前批量样本，如果超过限制，则返回并重置批量，否则返回 None。\n",
    "        \"\"\"\n",
    "        cur_len = info.max_len  # 当前样本的最大长度\n",
    "        max_len = max(self.max_len, cur_len)  # 更新当前批量的最大长度\n",
    "\n",
    "        # 如果当前批量加入新样本后超过限制，返回当前批量并重置\n",
    "        if max_len * (len(self._batch) + 1) > self._batch_size:\n",
    "            self._batch, result = [], self._batch  # 保存当前样本并清空\n",
    "            self._batch.append(info)  # 新批量的第一条样本\n",
    "            self.max_len = cur_len  # 当前批量的最大长度为新样本的最大长度\n",
    "            return result\n",
    "        else:\n",
    "            self.max_len = max_len\n",
    "            self._batch.append(info)  # 将新样本加入当前批量\n",
    "            return None\n",
    "\n",
    "    @property \n",
    "    def batch(self):\n",
    "        return self._batch"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "8455ce82888b56d4",
   "metadata": {
    "id": "8455ce82888b56d4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741005635533,
     "user_tz": -480,
     "elapsed": 1,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:48.382657Z",
     "start_time": "2025-03-06T07:17:48.376731Z"
    }
   },
   "source": [
    "from torch.utils.data import BatchSampler\n",
    "import numpy as np\n",
    "\n",
    "class TransformerBatchSampler(BatchSampler):\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 batch_size,\n",
    "                 shuffle_batch=False,\n",
    "                 clip_last_batch=False,\n",
    "                 seed=0):\n",
    "        \"\"\"\n",
    "        批量采样器，用于按批次生成样本。\n",
    "\n",
    "        :param dataset: 数据集\n",
    "        :param batch_size: 每个批次的样本数量\n",
    "        :param shuffle_batch: 是否对批次进行洗牌\n",
    "        :param clip_last_batch: 是否裁剪最后一个批次的数据（如果样本数不足一个完整批次）\n",
    "        :param seed: 随机数种子，用于保证可重复性\n",
    "        \"\"\"\n",
    "        self._dataset = dataset\n",
    "        self._batch_size = batch_size\n",
    "        self._shuffle_batch = shuffle_batch\n",
    "        self._clip_last_batch = clip_last_batch\n",
    "        self._seed = seed\n",
    "        self._random = np.random\n",
    "        self._random.seed(seed)\n",
    "\n",
    "        self._sample_infos = []\n",
    "        # 创建样本信息列表，包含每个样本的索引和长度信息\n",
    "        for i, data in enumerate(self._dataset):\n",
    "            lens = [len(data[0]), len(data[1])]  # 计算样本的源语言和目标语言的长度\n",
    "            self._sample_infos.append(SampleInfo(i, lens)) # 保存为 [索引，样本长度]的格式\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        对数据集中的样本进行排序，并使用 TokenBatchCreator 生成批次。\n",
    "\n",
    "        排序规则：先按源语言长度排序，若源语言长度相同，再按目标语言长度排序。\n",
    "        生成的批次如果未裁剪最后一批，则将剩余样本组成最后一个批次。\n",
    "        如果需要洗牌，则对批次进行洗牌。\n",
    "\n",
    "        :yield: 每个批次的样本在数据集中的索引\n",
    "        \"\"\"\n",
    "        # 按源语言和目标语言长度排序\n",
    "        infos = sorted(self._sample_infos, key=lambda x: (x.src_len, x.trg_len))\n",
    "        batch_infos = []\n",
    "        batch_creator = TokenBatchCreator(self._batch_size)  # 批量生成器\n",
    "\n",
    "        # 逐个样本加入批量生成器\n",
    "        for info in infos:\n",
    "            batch = batch_creator.append(info)\n",
    "            if batch is not None:\n",
    "                batch_infos.append(batch)  # 每当批次满足要求时，保存当前批次\n",
    "\n",
    "        # 如果未裁剪最后一个批次且有剩余样本，则将剩余样本作为最后一个批次\n",
    "        if not self._clip_last_batch and len(batch_creator.batch) != 0:\n",
    "            batch_infos.append(batch_creator.batch)\n",
    "\n",
    "        # 打乱批次顺序\n",
    "        if self._shuffle_batch:\n",
    "            self._random.shuffle(batch_infos)\n",
    "\n",
    "        # 记录批次数量\n",
    "        self.batch_number = len(batch_infos)\n",
    "\n",
    "        # 生成批次中的样本索引\n",
    "        for batch in batch_infos:\n",
    "            batch_indices = [info.i for info in batch]  # 获取当前批次的样本索引\n",
    "            yield batch_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回批次数量\n",
    "        \"\"\"\n",
    "        if hasattr(self, \"batch_number\"):\n",
    "            return self.batch_number\n",
    "\n",
    "        # 如果没有记录批次数量，计算批次样本数量\n",
    "        batch_number = (len(self._dataset) + self._batch_size - 1) // self._batch_size\n",
    "        return batch_number"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "733964ae297ff8d0",
   "metadata": {
    "id": "733964ae297ff8d0"
   },
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "id": "3d0c30ee420d4ec7",
   "metadata": {
    "id": "3d0c30ee420d4ec7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741005636883,
     "user_tz": -480,
     "elapsed": 1,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:49.397101Z",
     "start_time": "2025-03-06T07:17:49.392738Z"
    }
   },
   "source": [
    "from functools import partial # 固定collate_fct的tokenizer参数\n",
    "def collate_fct(batch, en_tokenizer, zh_tokenizer):\n",
    "    # 分别对源语言(英文)和目标语言(中文)进行处理\n",
    "    src_words = [pair[0].split() for pair in batch]\n",
    "    trg_words = [pair[1].split() for pair in batch]\n",
    "\n",
    "    # 使用中文tokenizer处理源语言\n",
    "    encoder_inputs, encoder_inputs_mask = zh_tokenizer.encode(\n",
    "        src_words, padding_first=False, add_bos=True, add_eos=True, return_mask=True\n",
    "    )\n",
    "\n",
    "    # 使用英文tokenizer处理目标语言\n",
    "    decoder_inputs = en_tokenizer.encode(\n",
    "        trg_words, padding_first=False, add_bos=True, add_eos=False, return_mask=False,\n",
    "    )\n",
    "\n",
    "    decoder_labels, decoder_labels_mask = en_tokenizer.encode(\n",
    "        trg_words, padding_first=False, add_bos=False, add_eos=True, return_mask=True\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"encoder_inputs\": encoder_inputs.to(device=device),\n",
    "        \"encoder_inputs_mask\": encoder_inputs_mask.to(device=device),\n",
    "        \"decoder_inputs\": decoder_inputs.to(device=device),\n",
    "        \"decoder_labels\": decoder_labels.to(device=device),\n",
    "        \"decoder_labels_mask\": decoder_labels_mask.to(device=device),\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "3a182c5d176092d0",
   "metadata": {
    "id": "3a182c5d176092d0"
   },
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04813e382404cd",
   "metadata": {
    "id": "8b04813e382404cd"
   },
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "id": "bd57c110b91e2fb4",
   "metadata": {
    "id": "bd57c110b91e2fb4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741005638446,
     "user_tz": -480,
     "elapsed": 45,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:50.587783Z",
     "start_time": "2025-03-06T07:17:50.581360Z"
    }
   },
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "    def __init__(self, config, vocab_size):\n",
    "        super().__init__()\n",
    "        # 获取配置中的超参数\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = config[\"d_model\"]\n",
    "        self.pad_idx = config[\"pad_idx\"]\n",
    "        dropout_rate = config[\"dropout\"]\n",
    "        self.max_length = config[\"max_length\"]\n",
    "\n",
    "        # 词嵌入层，padding_idx为pad的索引\n",
    "        self.word_embedding = nn.Embedding(self.vocab_size, self.hidden_size, padding_idx=self.pad_idx)\n",
    "        # 位置嵌入层，权重由get_positional_encoding计算得到\n",
    "        self.pos_embedding = nn.Embedding(\n",
    "            self.max_length,\n",
    "            self.hidden_size,\n",
    "            _weight=self.get_positional_encoding(self.max_length, self.hidden_size)\n",
    "        )\n",
    "        self.pos_embedding.weight.requires_grad_(False)  # 位置编码不可训练\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Dropout层\n",
    "\n",
    "    def get_word_embedding_weights(self):\n",
    "        # 返回词嵌入层的权重\n",
    "        return self.word_embedding.weight\n",
    "\n",
    "    @classmethod \n",
    "    def get_positional_encoding(self, max_length, hidden_size):\n",
    "        \"\"\"\n",
    "        计算位置编码\n",
    "        使用正弦和余弦函数生成位置编码矩阵\n",
    "        \"\"\"\n",
    "        pe = torch.zeros(max_length, hidden_size)\n",
    "        position = torch.arange(0, max_length).unsqueeze(1)  # 位置索引\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, hidden_size, 2) * -(torch.log(torch.Tensor([10000.0])) / hidden_size)\n",
    "        )\n",
    "        # 填充位置编码矩阵\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # 偶数列为sin\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # 奇数列为cos\n",
    "        return pe\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"\n",
    "        前向传播：词向量与位置编码加和\n",
    "        \"\"\"\n",
    "        seq_len = input_ids.shape[1]  # 序列长度\n",
    "        assert seq_len <= self.max_length, f\"序列长度超出最大限制 {self.max_length}\"\n",
    "\n",
    "        # 生成位置id\n",
    "        position_ids = torch.arange(seq_len, dtype=torch.long, device=input_ids.device) # [seq_len]\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)  # [batch_size, seq_len]\n",
    "\n",
    "        # 获取词嵌入和位置编码\n",
    "        word_embeds = self.word_embedding(input_ids) # [batch_size, seq_len, hidden_size]\n",
    "        pos_embeds = self.pos_embedding(position_ids) # [batch_size, seq_len, hidden_size]\n",
    "        embeds = word_embeds + pos_embeds  # 加和词向量和位置编码\n",
    "        embeds = self.dropout(embeds)  # 应用dropout\n",
    "        return embeds  # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "\n",
    "def plot_position_embedding(position_embedding):\n",
    "    \"\"\"\n",
    "    绘制位置编码矩阵\n",
    "    \"\"\"\n",
    "    plt.pcolormesh(position_embedding)  # 绘制矩阵\n",
    "    plt.xlabel('Depth')  # x轴为深度\n",
    "    plt.ylabel('Position')  # y轴为位置\n",
    "    plt.colorbar()  # 显示颜色条\n",
    "    plt.show()  # 显示图像"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "b1cb752dfcdf7f80",
   "metadata": {
    "id": "b1cb752dfcdf7f80"
   },
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f99de547b07abe2",
   "metadata": {
    "id": "8f99de547b07abe2"
   },
   "source": [
    "#### Scaled Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b0f0f610fd6a8ab",
   "metadata": {
    "id": "7b0f0f610fd6a8ab",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741005638679,
     "user_tz": -480,
     "elapsed": 1,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:50.747355Z",
     "start_time": "2025-03-06T07:17:50.739667Z"
    }
   },
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "@dataclass\n",
    "class AttentionOutput:\n",
    "    hidden_states: Tensor  # 注意力层的最终输出\n",
    "    attn_scores: Tensor    # 计算得到的注意力权重\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # 获取配置中的超参数\n",
    "        self.hidden_size = config[\"d_model\"]\n",
    "        self.num_heads = config[\"num_heads\"]\n",
    "\n",
    "        # 确保 hidden_size 可以被 num_heads 整除\n",
    "        assert self.hidden_size % self.num_heads == 0, \"Hidden size must be divisible by num_heads\"\n",
    "\n",
    "        self.head_dim = self.hidden_size // self.num_heads  # 每个头的维度\n",
    "\n",
    "        # 定义线性变换层\n",
    "        self.Wq = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.Wk = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.Wv = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.Wo = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "\n",
    "    def _split_heads(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        将输入张量拆分为多个头\n",
    "        \"\"\"\n",
    "        bs, seq_len, _ = x.shape\n",
    "        x = x.view(bs, seq_len, self.num_heads, self.head_dim)  # 调整形状\n",
    "        return x.permute(0, 2, 1, 3)  # 调整维度顺序\n",
    "\n",
    "    def _merge_heads(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        合并多个头的输出\n",
    "        \"\"\"\n",
    "        bs, _, seq_len, _ = x.shape\n",
    "        return x.permute(0, 2, 1, 3).reshape(bs, seq_len, self.hidden_size)\n",
    "\n",
    "    def forward(self, querys, keys, values, attn_mask=None) -> AttentionOutput:\n",
    "        \"\"\"\n",
    "        前向传播计算注意力机制\n",
    "        \"\"\"\n",
    "        # 线性变换并拆分为多个头\n",
    "        querys = self._split_heads(self.Wq(querys))  # [batch_size, num_heads, seq_len, head_dim]\n",
    "        keys = self._split_heads(self.Wk(keys))      # [batch_size, num_heads, seq_len, head_dim]\n",
    "        values = self._split_heads(self.Wv(values))  # [batch_size, num_heads, seq_len, head_dim]\n",
    "\n",
    "        # 计算 Q 和 K 之间的点积注意力分数\n",
    "        qk_logits = torch.matmul(querys, keys.mT)  # [batch_size, num_heads, seq_len, seq_len]\n",
    "\n",
    "        # 如果提供了mask，应用它\n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask[:, :, : querys.shape[-2], : keys.shape[-2]]  # 调整mask的大小\n",
    "            qk_logits += attn_mask * -1e9  # mask部分置为负无穷\n",
    "\n",
    "        # 计算注意力权重\n",
    "        attn_scores = F.softmax(qk_logits / (self.head_dim**0.5), dim=-1)  # [batch_size, num_heads, seq_len, seq_len]\n",
    "\n",
    "        # 加权求和\n",
    "        embeds = torch.matmul(attn_scores, values)  # [batch_size, num_heads, seq_len, head_dim]\n",
    "\n",
    "        # 合并头的输出并通过输出投影层\n",
    "        embeds = self.Wo(self._merge_heads(embeds))  # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        return AttentionOutput(hidden_states=embeds, attn_scores=attn_scores)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "5f1c8ed655b4ba8f",
   "metadata": {
    "id": "5f1c8ed655b4ba8f"
   },
   "source": [
    "#### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "id": "315d0c77f5c2652c",
   "metadata": {
    "id": "315d0c77f5c2652c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741005638681,
     "user_tz": -480,
     "elapsed": 1,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:50.754844Z",
     "start_time": "2025-03-06T07:17:50.748624Z"
    }
   },
   "source": [
    "@dataclass\n",
    "class TransformerBlockOutput:\n",
    "    # 当前块的输出（隐藏状态）和自/交叉注意力的分数\n",
    "    hidden_states: Tensor\n",
    "    self_attn_scores: Tensor\n",
    "    cross_attn_scores: Optional[Tensor] = None\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config, add_cross_attention=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # 获取配置中的超参数\n",
    "        self.hidden_size = config[\"d_model\"]\n",
    "        self.num_heads = config[\"num_heads\"]\n",
    "        dropout_rate = config[\"dropout\"]\n",
    "        ffn_dim = config[\"dim_feedforward\"]\n",
    "        eps = config[\"layer_norm_eps\"]\n",
    "\n",
    "        # 自注意力机制\n",
    "        self.self_atten = MultiHeadAttention(config)\n",
    "        self.self_ln = nn.LayerNorm(self.hidden_size, eps=eps)\n",
    "        self.self_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # 交叉注意力机制（仅解码器中使用）\n",
    "        if add_cross_attention:\n",
    "            self.cross_atten = MultiHeadAttention(config)\n",
    "            self.cross_ln = nn.LayerNorm(self.hidden_size, eps=eps)\n",
    "            self.cross_dropout = nn.Dropout(dropout_rate)\n",
    "        else:\n",
    "            self.cross_atten = None\n",
    "\n",
    "        # 前馈神经网络（FFN）\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, ffn_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ffn_dim, self.hidden_size),\n",
    "        )\n",
    "        self.ffn_ln = nn.LayerNorm(self.hidden_size, eps=eps)\n",
    "        self.ffn_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, hidden_states, attn_mask=None, encoder_outputs=None, cross_attn_mask=None):\n",
    "        # 自注意力机制\n",
    "        self_atten_output = self.self_atten(\n",
    "            hidden_states, hidden_states, hidden_states, attn_mask\n",
    "        )\n",
    "        self_embeds = self.self_ln(\n",
    "            hidden_states + self.self_dropout(self_atten_output.hidden_states)\n",
    "        )\n",
    "\n",
    "        # 交叉注意力机制（解码器中）\n",
    "        if self.cross_atten is not None:\n",
    "            assert encoder_outputs is not None  # 使用交叉注意力时，必须传入编码器输出\n",
    "            cross_atten_output = self.cross_atten(\n",
    "                self_embeds, encoder_outputs, encoder_outputs, cross_attn_mask\n",
    "            )\n",
    "            cross_embeds = self.cross_ln(\n",
    "                self_embeds + self.cross_dropout(cross_atten_output.hidden_states)\n",
    "            )\n",
    "\n",
    "        # 前馈神经网络（FFN）\n",
    "        embeds = cross_embeds if self.cross_atten is not None else self_embeds\n",
    "        ffn_output = self.ffn(embeds)\n",
    "        embeds = self.ffn_ln(embeds + self.ffn_dropout(ffn_output))\n",
    "\n",
    "        # 返回 TransformerBlockOutput\n",
    "        return TransformerBlockOutput(\n",
    "            hidden_states=embeds,\n",
    "            self_attn_scores=self_atten_output.attn_scores,\n",
    "            cross_attn_scores=cross_atten_output.attn_scores if self.cross_atten is not None else None,\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "f6c06503b7815611",
   "metadata": {
    "id": "f6c06503b7815611"
   },
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "id": "70aa1fe1c5d89641",
   "metadata": {
    "id": "70aa1fe1c5d89641",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741005638682,
     "user_tz": -480,
     "elapsed": 1,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:50.760955Z",
     "start_time": "2025-03-06T07:17:50.755880Z"
    }
   },
   "source": [
    "from typing import List\n",
    "\n",
    "@dataclass  # 存储TransformerEncoder的输出\n",
    "class TransformerEncoderOutput:\n",
    "    last_hidden_states: Tensor  # 最后一层的隐藏状态，包含上下文信息\n",
    "    attn_scores: List[Tensor]   # 每层的注意力分数，用于分析每层的关注点\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        # 获取编码器层数\n",
    "        self.num_layers = config[\"num_encoder_layers\"]\n",
    "\n",
    "        # 创建包含多个TransformerBlock的列表，每个TransformerBlock代表编码器的一层\n",
    "        self.layers = nn.ModuleList(\n",
    "            [TransformerBlock(config) for _ in range(self.num_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, encoder_inputs_embeds, attn_mask=None) -> TransformerEncoderOutput:\n",
    "        attn_scores = []  # 存储每层的自注意力分数\n",
    "        embeds = encoder_inputs_embeds  # 输入嵌入作为编码器的第一层输入\n",
    "\n",
    "        # 遍历每一层TransformerBlock\n",
    "        for layer in self.layers:\n",
    "            block_outputs = layer(embeds, attn_mask=attn_mask)  # 当前层输出\n",
    "\n",
    "            embeds = block_outputs.hidden_states  # 更新下一层输入\n",
    "            attn_scores.append(block_outputs.self_attn_scores)  # 保存注意力分数\n",
    "\n",
    "        # 返回最后一层输出和所有层的注意力分数\n",
    "        return TransformerEncoderOutput(\n",
    "            last_hidden_states=embeds,  # 最后一层的输出\n",
    "            attn_scores=attn_scores  # 所有层的注意力分数\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "138185edf3d182fa",
   "metadata": {
    "id": "138185edf3d182fa"
   },
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "id": "40b6404562f388b9",
   "metadata": {
    "id": "40b6404562f388b9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741005638685,
     "user_tz": -480,
     "elapsed": 2,
     "user": {
      "displayName": "Seagal",
      "userId": "11790859596784159614"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-03-06T07:17:50.768173Z",
     "start_time": "2025-03-06T07:17:50.761960Z"
    }
   },
   "source": [
    "@dataclass\n",
    "class TransformerDecoderOutput:\n",
    "    last_hidden_states: Tensor  # 最后一层的隐藏状态\n",
    "    self_attn_scores: List[Tensor]  # 每层的自注意力分数\n",
    "    cross_attn_scores: List[Tensor]  # 每层的交叉注意力分数\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        # 获取解码器层数\n",
    "        self.num_layers = config[\"num_decoder_layers\"]\n",
    "\n",
    "        # 创建多个TransformerBlock，每层都有交叉注意力机制\n",
    "        self.layers = nn.ModuleList(\n",
    "            [TransformerBlock(config, add_cross_attention=True) for _ in range(self.num_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, decoder_inputs_embeds, encoder_outputs, attn_mask=None, cross_attn_mask=None) -> TransformerDecoderOutput:\n",
    "        self_attn_scores = []  # 存储每层的自注意力分数\n",
    "        cross_attn_scores = []  # 存储每层的交叉注意力分数\n",
    "        embeds = decoder_inputs_embeds  # 解码器输入嵌入\n",
    "\n",
    "        # 遍历每一层的TransformerBlock\n",
    "        for layer in self.layers:\n",
    "            # 前向传播，通过自注意力和交叉注意力机制\n",
    "            block_outputs = layer(\n",
    "                embeds,\n",
    "                attn_mask=attn_mask,\n",
    "                encoder_outputs=encoder_outputs,\n",
    "                cross_attn_mask=cross_attn_mask,\n",
    "            )\n",
    "            embeds = block_outputs.hidden_states  # 更新输入为当前层输出\n",
    "\n",
    "            self_attn_scores.append(block_outputs.self_attn_scores)  # 保存自注意力分数\n",
    "            cross_attn_scores.append(block_outputs.cross_attn_scores)  # 保存交叉注意力分数\n",
    "\n",
    "        # 返回最后一层的隐藏状态和每层的注意力分数\n",
    "        return TransformerDecoderOutput(\n",
    "            last_hidden_states=embeds,\n",
    "            self_attn_scores=self_attn_scores,\n",
    "            cross_attn_scores=cross_attn_scores\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "954c5e61eaa76cbc",
   "metadata": {
    "id": "954c5e61eaa76cbc"
   },
   "source": [
    "#### Transformer Model"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 24,
   "source": [
    "@dataclass\n",
    "class TransformerOutput:\n",
    "    logits: Tensor  # 模型的预测输出 logits\n",
    "    encoder_last_hidden_states: Tensor  # 编码器的最终隐藏状态\n",
    "    encoder_attn_scores: List[Tensor]  # 编码器各层的自注意力得分\n",
    "    decoder_last_hidden_states: Tensor  # 解码器的最终隐藏状态\n",
    "    decoder_self_attn_scores: List[Tensor]  # 解码器自注意力得分\n",
    "    decoder_cross_attn_scores: List[Tensor]  # 解码器交叉注意力得分\n",
    "    preds: Optional[Tensor] = None  # 推理时的预测结果\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # 模型的各项配置初始化\n",
    "        self.hidden_size = config[\"d_model\"]  # Transformer模型中的隐藏层维度\n",
    "        self.num_encoder_layers = config[\"num_encoder_layers\"]  # 编码器层数\n",
    "        self.num_decoder_layers = config[\"num_decoder_layers\"]  # 解码器层数\n",
    "        self.pad_idx = config[\"pad_idx\"]  # padding 标记的索引\n",
    "        self.bos_idx = config[\"bos_idx\"]  # 句子开始标记的索引\n",
    "        self.eos_idx = config[\"eos_idx\"]  # 句子结束标记的索引\n",
    "        self.en_vocab_size = config[\"en_vocab_size\"]  # 英文词表大小\n",
    "        self.zh_vocab_size = config[\"zh_vocab_size\"]  # 中文词表大小\n",
    "        self.dropout_rate = config[\"dropout\"]  # Dropout比例\n",
    "        self.max_length = config[\"max_length\"]  # 最大序列长度\n",
    "\n",
    "        # 初始化源语言(中文))和目标语言(英文)的嵌入层\n",
    "        self.src_embedding = TransformerEmbedding(config, vocab_size=self.zh_vocab_size)\n",
    "        self.trg_embedding = TransformerEmbedding(config, vocab_size=self.en_vocab_size)\n",
    "\n",
    "        # 输出层的线性变换，输出的维度为中文词表大小\n",
    "        self.linear = nn.Linear(self.hidden_size, self.en_vocab_size)\n",
    "\n",
    "        # 初始化编码器和解码器\n",
    "        self.encoder = TransformerEncoder(config)\n",
    "        self.decoder = TransformerDecoder(config)\n",
    "\n",
    "        # 权重初始化\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"初始化网络权重\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                # 使用 Xavier 均匀分布初始化权重\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz: int) -> Tensor:\n",
    "        \"\"\"生成解码器的下三角掩码，用于自回归解码\"\"\"\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 0).transpose(-1, -2).bool()  # 下三角掩码\n",
    "        return mask\n",
    "\n",
    "    def forward(self, encoder_inputs, decoder_inputs, encoder_inputs_mask=None) -> TransformerOutput:\n",
    "        \"\"\"\n",
    "        Transformer前向传播\n",
    "        1. 将输入的源语言和目标语言进行嵌入。\n",
    "        2. 通过编码器处理源语言输入。\n",
    "        3. 通过解码器生成目标语言的输出。\n",
    "        \"\"\"\n",
    "        if encoder_inputs_mask is None:\n",
    "            # 如果没有提供mask，则根据padding索引生成\n",
    "            encoder_inputs_mask = encoder_inputs.eq(self.pad_idx)\n",
    "        encoder_inputs_mask = encoder_inputs_mask.unsqueeze(1).unsqueeze(2)  # 扩展mask维度，以适应多头注意力\n",
    "\n",
    "        # 生成解码器掩码（防止信息泄漏）\n",
    "        look_ahead_mask = self.generate_square_subsequent_mask(decoder_inputs.shape[1]).unsqueeze(0).unsqueeze(0).to(decoder_inputs.device)\n",
    "        decoder_inputs_mask = decoder_inputs.eq(self.pad_idx).unsqueeze(1).unsqueeze(2) + look_ahead_mask\n",
    "\n",
    "        # 编码阶段：将源语言输入映射到嵌入空间\n",
    "        encoder_inputs_embeds = self.src_embedding(encoder_inputs)\n",
    "        encoder_outputs = self.encoder(encoder_inputs_embeds, encoder_inputs_mask)\n",
    "\n",
    "        # 解码阶段：将目标语言输入映射到嵌入空间\n",
    "        decoder_inputs_embeds = self.trg_embedding(decoder_inputs)\n",
    "        decoder_outputs = self.decoder(\n",
    "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
    "            encoder_outputs=encoder_outputs.last_hidden_states,\n",
    "            attn_mask=decoder_inputs_mask,\n",
    "            cross_attn_mask=encoder_inputs_mask,\n",
    "        )\n",
    "\n",
    "        # 将解码器的输出通过线性变换映射到目标语言的词表大小\n",
    "        logits = self.linear(decoder_outputs.last_hidden_states)\n",
    "\n",
    "        return TransformerOutput(\n",
    "            logits=logits,\n",
    "            encoder_last_hidden_states=encoder_outputs.last_hidden_states,\n",
    "            encoder_attn_scores=encoder_outputs.attn_scores,\n",
    "            decoder_last_hidden_states=decoder_outputs.last_hidden_states,\n",
    "            decoder_self_attn_scores=decoder_outputs.self_attn_scores,\n",
    "            decoder_cross_attn_scores=decoder_outputs.cross_attn_scores,\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def infer(self, encoder_inputs, encoder_inputs_mask=None) -> Tensor:\n",
    "        \"\"\"推理：生成目标语言的翻译结果\"\"\"\n",
    "        if encoder_inputs_mask is None:\n",
    "            encoder_inputs_mask = encoder_inputs.eq(self.pad_idx)  # 根据padding生成mask\n",
    "        encoder_inputs_mask = encoder_inputs_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # 生成解码器的掩码（自回归）\n",
    "        look_ahead_mask = self.generate_square_subsequent_mask(self.max_length).unsqueeze(0).unsqueeze(0).to(encoder_inputs.device)\n",
    "\n",
    "        # 编码阶段\n",
    "        encoder_inputs_embeds = self.src_embedding(encoder_inputs)\n",
    "        encoder_outputs = self.encoder(encoder_inputs_embeds)\n",
    "\n",
    "        # 解码阶段：生成目标语言翻译\n",
    "        decoder_inputs = torch.Tensor([self.bos_idx] * encoder_inputs.shape[0]).reshape(-1, 1).long().to(device=encoder_inputs.device)\n",
    "        for cur_len in tqdm(range(1, self.max_length + 1)):\n",
    "            decoder_inputs_embeds = self.trg_embedding(decoder_inputs)\n",
    "            decoder_outputs = self.decoder(\n",
    "                decoder_inputs_embeds=decoder_inputs_embeds,\n",
    "                encoder_outputs=encoder_outputs.last_hidden_states,\n",
    "                attn_mask=look_ahead_mask[:, :, :cur_len, :cur_len],\n",
    "            )\n",
    "            logits = self.linear(decoder_outputs.last_hidden_states)\n",
    "            next_token = logits.argmax(dim=-1)[:, -1:]  # 选择下一个最可能的token\n",
    "            decoder_inputs = torch.cat([decoder_inputs, next_token], dim=-1)  # 将token加入解码输入中\n",
    "\n",
    "            # 如果所有样本的解码器输出达到结束标记，则停止解码\n",
    "            if all((decoder_inputs == self.eos_idx).sum(dim=-1) > 0):\n",
    "                break\n",
    "\n",
    "        return TransformerOutput(\n",
    "            preds=decoder_inputs[:, 1:],  # 排除开始标记，返回最终的预测结果\n",
    "            logits=logits,\n",
    "            encoder_last_hidden_states=encoder_outputs.last_hidden_states,\n",
    "            encoder_attn_scores=encoder_outputs.attn_scores,\n",
    "            decoder_last_hidden_states=decoder_outputs.last_hidden_states,\n",
    "            decoder_self_attn_scores=decoder_outputs.self_attn_scores,\n",
    "            decoder_cross_attn_scores=decoder_outputs.cross_attn_scores,\n",
    "        )"
   ],
   "id": "ce5c0ec31017265f"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "5ad4c47414d349c1b44fb38afc8449a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7e755097ad94a27baa4908d85564fe3",
       "IPY_MODEL_c336ff919ad84c06b4d435af8812da34",
       "IPY_MODEL_db072193241b4176abd7dff003ad4c22"
      ],
      "layout": "IPY_MODEL_60dc9410aadc4e98a65b2621fc2bd294"
     }
    },
    "a7e755097ad94a27baa4908d85564fe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8a5c441580f4fbba993d85e94ab7f25",
      "placeholder": "​",
      "style": "IPY_MODEL_232d53940b5844d7a40ad03c7ece7459",
      "value": "100%"
     }
    },
    "c336ff919ad84c06b4d435af8812da34": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b83a47e3df014d6aa927559f0240d248",
      "max": 47609,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8739091f49cb45a3a32f4e6610337024",
      "value": 47609
     }
    },
    "db072193241b4176abd7dff003ad4c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c301ed4cc6b642c5be5d5d4f03b5696d",
      "placeholder": "​",
      "style": "IPY_MODEL_cdbcd22293aa46318e72ad3eedf979ab",
      "value": " 47609/47609 [00:00&lt;00:00, 579837.10it/s]"
     }
    },
    "60dc9410aadc4e98a65b2621fc2bd294": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8a5c441580f4fbba993d85e94ab7f25": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "232d53940b5844d7a40ad03c7ece7459": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b83a47e3df014d6aa927559f0240d248": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8739091f49cb45a3a32f4e6610337024": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c301ed4cc6b642c5be5d5d4f03b5696d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdbcd22293aa46318e72ad3eedf979ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9637c960540e482a91130e54e64d4a32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_047bb5c224b94380b292ba1b133e0417",
       "IPY_MODEL_7a8b3dc358154d25aabfa8ad218a19bc",
       "IPY_MODEL_3a17919d1d854783940dbf23d7061f36"
      ],
      "layout": "IPY_MODEL_89a51a19525649308a9fc3d068ba4319"
     }
    },
    "047bb5c224b94380b292ba1b133e0417": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ceb3853559e548dc85979b470b4e6143",
      "placeholder": "​",
      "style": "IPY_MODEL_da9d413568a54d0d8dc97f7db1fcaf16",
      "value": "100%"
     }
    },
    "7a8b3dc358154d25aabfa8ad218a19bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d0364127f6b48d4aac7adfc68b21752",
      "max": 54986,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_65093a24b53041efb05248534b2f4e3e",
      "value": 54986
     }
    },
    "3a17919d1d854783940dbf23d7061f36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33d480e964954516a0d3a0767204e79b",
      "placeholder": "​",
      "style": "IPY_MODEL_5eae7f34d8a744aebdeada57727b0361",
      "value": " 54986/54986 [00:00&lt;00:00, 798205.81it/s]"
     }
    },
    "89a51a19525649308a9fc3d068ba4319": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ceb3853559e548dc85979b470b4e6143": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da9d413568a54d0d8dc97f7db1fcaf16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d0364127f6b48d4aac7adfc68b21752": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65093a24b53041efb05248534b2f4e3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "33d480e964954516a0d3a0767204e79b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5eae7f34d8a744aebdeada57727b0361": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43e5226f9dad4f2c9c9ded3f5bb8e512": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dbac23e3e3264da9aaf5c750f3280727",
       "IPY_MODEL_511b524274ad41eb8c4eabcb0eec91c9",
       "IPY_MODEL_d08459cdd3e64f0a9d9fd36e2d4b5125"
      ],
      "layout": "IPY_MODEL_1d11f7fb05d3495d947aebd4a69a7549"
     }
    },
    "dbac23e3e3264da9aaf5c750f3280727": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_783985e729694b2580ec44021bdc619f",
      "placeholder": "​",
      "style": "IPY_MODEL_d9e0dbfd44084743b76ae034a69b44fe",
      "value": " 97%"
     }
    },
    "511b524274ad41eb8c4eabcb0eec91c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_feacff718326402bacd87fe2fdc82df5",
      "max": 69560,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd31c960ae324a45b361868c8806846a",
      "value": 67499
     }
    },
    "d08459cdd3e64f0a9d9fd36e2d4b5125": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_869c946063df4a03abdd46381444bc1c",
      "placeholder": "​",
      "style": "IPY_MODEL_9a22bc23493e45ff845322f4319de970",
      "value": " 67499/69560 [2:53:50&lt;05:22,  6.39it/s, epoch=37, loss=2.99, val_loss=3.1]"
     }
    },
    "1d11f7fb05d3495d947aebd4a69a7549": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "783985e729694b2580ec44021bdc619f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9e0dbfd44084743b76ae034a69b44fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "feacff718326402bacd87fe2fdc82df5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd31c960ae324a45b361868c8806846a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "869c946063df4a03abdd46381444bc1c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a22bc23493e45ff845322f4319de970": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
